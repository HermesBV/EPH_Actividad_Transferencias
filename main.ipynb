{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "1b74e314",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from pandas.plotting import table\n",
    "import numpy as np  \n",
    "import matplotlib.pyplot as plt\n",
    "import openpyxl\n",
    "from IPython.display import HTML\n",
    "import pingouin as pg\n",
    "import os\n",
    "from scipy.stats import chi2_contingency\n",
    "import statsmodels.api as sm\n",
    "import statsmodels.formula.api as smf\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3e67e32a",
   "metadata": {},
   "outputs": [],
   "source": [
    "xl_usu = 'usu_individual_T125.xlsx'  \n",
    "dfusu = pd.read_excel(xl_usu)\n",
    "dfusu = dfusu.loc[:, ['CODUSU','NRO_HOGAR','COMPONENTE', 'ESTADO','V5_01_M','V5_02_M','V5_03_M','PONDERA']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "96a45606",
   "metadata": {},
   "outputs": [],
   "source": [
    "xl_hog = 'usu_hogar_T125.xlsx'  \n",
    "dfhog = pd.read_excel(xl_hog)\n",
    "dfhog = dfhog.loc[:, ['CODUSU','NRO_HOGAR','DECIFR','REGION','V5_01','V5_02','V5_03']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5ad8a59b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CODUSU</th>\n",
       "      <th>NRO_HOGAR</th>\n",
       "      <th>DECIFR</th>\n",
       "      <th>REGION</th>\n",
       "      <th>V5_01</th>\n",
       "      <th>V5_02</th>\n",
       "      <th>V5_03</th>\n",
       "      <th>V5</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>TQRMNOQVSHKOLNCDEGGFB00858441</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>42</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>TQSMNORTSHMOLTCDEGGFB00877605</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>42</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>TQRMNOQQXHMMMLCDEGGFB00877606</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>42</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>TQRMNOTTWHMMLOCDEFIAH00877819</td>\n",
       "      <td>1</td>\n",
       "      <td>12</td>\n",
       "      <td>43</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>TQRMNORQQHLMKOCDEHIBB00853810</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>40</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                          CODUSU  NRO_HOGAR  DECIFR  REGION  V5_01  V5_02  \\\n",
       "0  TQRMNOQVSHKOLNCDEGGFB00858441          1       1      42      2      2   \n",
       "1  TQSMNORTSHMOLTCDEGGFB00877605          1       6      42      2      2   \n",
       "2  TQRMNOQQXHMMMLCDEGGFB00877606          1       4      42      2      2   \n",
       "3  TQRMNOTTWHMMLOCDEFIAH00877819          1      12      43      2      2   \n",
       "4  TQRMNORQQHLMKOCDEHIBB00853810          2       1      40      2      2   \n",
       "\n",
       "   V5_03  V5  \n",
       "0      2   2  \n",
       "1      2   2  \n",
       "2      2   2  \n",
       "3      2   2  \n",
       "4      2   2  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# V5 = 1 si ALGUNA variable es 1, 2 solo si TODAS son 2\n",
    "dfhog['V5'] = 2  # Inicializar con 2 (asumiendo que todas son 2)\n",
    "\n",
    "# Si ALGUNA variable es 1, entonces V5 = 1\n",
    "mask_alguna_1 = (dfhog['V5_01'] == 1) | (dfhog['V5_02'] == 1) | (dfhog['V5_03'] == 1)\n",
    "dfhog.loc[mask_alguna_1, 'V5'] = 1\n",
    "\n",
    "#print(dfhog['V5'].value_counts().sort_index())\n",
    "dfhog.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "cb73e748",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DECIFR\n",
      "1    1457\n",
      "4    1350\n",
      "2    1333\n",
      "5    1287\n",
      "3    1273\n",
      "Name: count, dtype: int64\n",
      "ESTADO\n",
      "1    20076\n",
      "3    18866\n",
      "2     1381\n",
      "Name: count, dtype: int64\n",
      "---------------------------------------------------\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 6700 entries, 0 to 15979\n",
      "Data columns (total 8 columns):\n",
      " #   Column     Non-Null Count  Dtype \n",
      "---  ------     --------------  ----- \n",
      " 0   CODUSU     6700 non-null   object\n",
      " 1   NRO_HOGAR  6700 non-null   int64 \n",
      " 2   DECIFR     6700 non-null   int64 \n",
      " 3   REGION     6700 non-null   int64 \n",
      " 4   V5_01      6700 non-null   int64 \n",
      " 5   V5_02      6700 non-null   int64 \n",
      " 6   V5_03      6700 non-null   int64 \n",
      " 7   V5         6700 non-null   int64 \n",
      "dtypes: int64(7), object(1)\n",
      "memory usage: 471.1+ KB\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 40323 entries, 0 to 45424\n",
      "Data columns (total 8 columns):\n",
      " #   Column      Non-Null Count  Dtype \n",
      "---  ------      --------------  ----- \n",
      " 0   CODUSU      40323 non-null  object\n",
      " 1   NRO_HOGAR   40323 non-null  int64 \n",
      " 2   COMPONENTE  40323 non-null  int64 \n",
      " 3   ESTADO      40323 non-null  int64 \n",
      " 4   V5_01_M     40323 non-null  int64 \n",
      " 5   V5_02_M     40323 non-null  int64 \n",
      " 6   V5_03_M     40323 non-null  int64 \n",
      " 7   PONDERA     40323 non-null  int64 \n",
      "dtypes: int64(7), object(1)\n",
      "memory usage: 2.8+ MB\n"
     ]
    }
   ],
   "source": [
    "#hogares: filtrar 50% más pobre (0 y 12)\n",
    "\n",
    "dfhog_pobre = dfhog[dfhog['DECIFR'].isin([1, 2, 3, 4, 5])]\n",
    "print(dfhog_pobre['DECIFR'].value_counts())\n",
    "\n",
    "#persona: filtrar por Estado 1 (ocupado), 2 (desocupado) y 3 (inactivo)\n",
    "dfusu = dfusu[dfusu['ESTADO'].isin([1, 2, 3])]\n",
    "print(dfusu['ESTADO'].value_counts())\n",
    "\n",
    "print(\"---------------------------------------------------\")\n",
    "dfhog_pobre.info()\n",
    "dfusu.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f4c0d12c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 14030 entries, 0 to 14029\n",
      "Data columns (total 14 columns):\n",
      " #   Column      Non-Null Count  Dtype \n",
      "---  ------      --------------  ----- \n",
      " 0   CODUSU      14030 non-null  object\n",
      " 1   NRO_HOGAR   14030 non-null  int64 \n",
      " 2   DECIFR      14030 non-null  int64 \n",
      " 3   REGION      14030 non-null  int64 \n",
      " 4   V5_01       14030 non-null  int64 \n",
      " 5   V5_02       14030 non-null  int64 \n",
      " 6   V5_03       14030 non-null  int64 \n",
      " 7   V5          14030 non-null  int64 \n",
      " 8   COMPONENTE  14030 non-null  int64 \n",
      " 9   ESTADO      14030 non-null  int64 \n",
      " 10  V5_01_M     14030 non-null  int64 \n",
      " 11  V5_02_M     14030 non-null  int64 \n",
      " 12  V5_03_M     14030 non-null  int64 \n",
      " 13  PONDERA     14030 non-null  int64 \n",
      "dtypes: int64(13), object(1)\n",
      "memory usage: 1.5+ MB\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CODUSU</th>\n",
       "      <th>NRO_HOGAR</th>\n",
       "      <th>DECIFR</th>\n",
       "      <th>REGION</th>\n",
       "      <th>V5_01</th>\n",
       "      <th>V5_02</th>\n",
       "      <th>V5_03</th>\n",
       "      <th>V5</th>\n",
       "      <th>COMPONENTE</th>\n",
       "      <th>ESTADO</th>\n",
       "      <th>V5_01_M</th>\n",
       "      <th>V5_02_M</th>\n",
       "      <th>V5_03_M</th>\n",
       "      <th>PONDERA</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>TQRMNOQVSHKOLNCDEGGFB00858441</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>42</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>526</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>TQRMNOQVSHKOLNCDEGGFB00858441</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>42</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>526</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>TQRMNOQQXHMMMLCDEGGFB00877606</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>42</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>446</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>TQRMNOQQXHMMMLCDEGGFB00877606</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>42</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>446</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>TQRMNORQQHLMKOCDEHIBB00853810</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>40</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>132</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>TQRMNOTPYHMOLQCDEFMDB00877823</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>43</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>199</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>TQRMNOTPYHMOLQCDEFMDB00877823</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>43</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>199</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>TQRMNORVVHLLLPCDEFMDB00852190</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>43</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>146</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>TQRMNOQTTHKMKSCDEFMDB00857883</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>43</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>234</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>TQRMNOPXWHMOKSCDEOJAH00877825</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>44</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>113</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>TQRMNORPXHLLKRCDEOJAH00856304</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>44</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>92</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>TQRMNORPXHLLKRCDEOJAH00856304</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>44</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>92</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>TQRMNORPXHLLKRCDEOJAH00856304</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>44</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>92</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>TQRMNOPWTHLOKTCDEOJAH00856786</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>44</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>46</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>TQSMNOPSYHKMMLCDEFKID00861533</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>43</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>720</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>TQSMNOPSYHKMMLCDEFKID00861533</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>43</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>60000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>720</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>TQRMNOSVSHKMMLCDEFKID00861389</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>43</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>586</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>TQRMNOSVSHKMMLCDEFKID00861389</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>43</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>586</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>TQRMNOSUXHLLLUCDEFKID00861457</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>43</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1770</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>TQRMNOPSXHLMLMCDEIJAH00855495</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3440</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                           CODUSU  NRO_HOGAR  DECIFR  REGION  V5_01  V5_02  \\\n",
       "0   TQRMNOQVSHKOLNCDEGGFB00858441          1       1      42      2      2   \n",
       "1   TQRMNOQVSHKOLNCDEGGFB00858441          1       1      42      2      2   \n",
       "2   TQRMNOQQXHMMMLCDEGGFB00877606          1       4      42      2      2   \n",
       "3   TQRMNOQQXHMMMLCDEGGFB00877606          1       4      42      2      2   \n",
       "4   TQRMNORQQHLMKOCDEHIBB00853810          2       1      40      2      2   \n",
       "5   TQRMNOTPYHMOLQCDEFMDB00877823          1       5      43      2      2   \n",
       "6   TQRMNOTPYHMOLQCDEFMDB00877823          1       5      43      2      2   \n",
       "7   TQRMNORVVHLLLPCDEFMDB00852190          1       3      43      2      2   \n",
       "8   TQRMNOQTTHKMKSCDEFMDB00857883          1       3      43      2      2   \n",
       "9   TQRMNOPXWHMOKSCDEOJAH00877825          1       3      44      2      2   \n",
       "10  TQRMNORPXHLLKRCDEOJAH00856304          1       5      44      2      2   \n",
       "11  TQRMNORPXHLLKRCDEOJAH00856304          1       5      44      2      2   \n",
       "12  TQRMNORPXHLLKRCDEOJAH00856304          1       5      44      2      2   \n",
       "13  TQRMNOPWTHLOKTCDEOJAH00856786          1       2      44      2      2   \n",
       "14  TQSMNOPSYHKMMLCDEFKID00861533          1       4      43      1      2   \n",
       "15  TQSMNOPSYHKMMLCDEFKID00861533          1       4      43      1      2   \n",
       "16  TQRMNOSVSHKMMLCDEFKID00861389          1       3      43      2      2   \n",
       "17  TQRMNOSVSHKMMLCDEFKID00861389          1       3      43      2      2   \n",
       "18  TQRMNOSUXHLLLUCDEFKID00861457          1       1      43      2      2   \n",
       "19  TQRMNOPSXHLMLMCDEIJAH00855495          1       3       1      2      2   \n",
       "\n",
       "    V5_03  V5  COMPONENTE  ESTADO  V5_01_M  V5_02_M  V5_03_M  PONDERA  \n",
       "0       2   2           1       1        0        0        0      526  \n",
       "1       2   2           2       3        0        0        0      526  \n",
       "2       2   2           1       3        0        0        0      446  \n",
       "3       2   2           2       3        0        0        0      446  \n",
       "4       2   2           1       3        0        0        0      132  \n",
       "5       2   2           1       1        0        0        0      199  \n",
       "6       2   2           2       1        0        0        0      199  \n",
       "7       2   2           1       3        0        0        0      146  \n",
       "8       2   2           1       1        0        0        0      234  \n",
       "9       2   2           1       1        0        0        0      113  \n",
       "10      2   2           1       2        0        0        0       92  \n",
       "11      2   2           2       3        0        0        0       92  \n",
       "12      2   2           3       3        0        0        0       92  \n",
       "13      2   2           1       3        0        0        0       46  \n",
       "14      2   1           1       1        0        0        0      720  \n",
       "15      2   1           2       1    60000        0        0      720  \n",
       "16      2   2           1       3        0        0        0      586  \n",
       "17      2   2           2       3        0        0        0      586  \n",
       "18      2   2           1       3        0        0        0     1770  \n",
       "19      2   2           1       3        0        0        0     3440  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Juntar tablas (left hogares pobres, right individuos)\n",
    "df_join_pobre = dfhog_pobre.merge(dfusu, how='left', on=['CODUSU', 'NRO_HOGAR'])\n",
    "df_join_pobre.info()\n",
    "df_join_pobre.head(20)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "45ada7d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 14030 entries, 0 to 14029\n",
      "Data columns (total 15 columns):\n",
      " #   Column      Non-Null Count  Dtype \n",
      "---  ------      --------------  ----- \n",
      " 0   CODUSU      14030 non-null  object\n",
      " 1   NRO_HOGAR   14030 non-null  int64 \n",
      " 2   DECIFR      14030 non-null  int64 \n",
      " 3   REGION      14030 non-null  int64 \n",
      " 4   V5_01       14030 non-null  int64 \n",
      " 5   V5_02       14030 non-null  int64 \n",
      " 6   V5_03       14030 non-null  int64 \n",
      " 7   V5          14030 non-null  int64 \n",
      " 8   COMPONENTE  14030 non-null  int64 \n",
      " 9   ESTADO      14030 non-null  int64 \n",
      " 10  V5_01_M     14030 non-null  int64 \n",
      " 11  V5_02_M     14030 non-null  int64 \n",
      " 12  V5_03_M     14030 non-null  int64 \n",
      " 13  PONDERA     14030 non-null  int64 \n",
      " 14  UID         14030 non-null  object\n",
      "dtypes: int64(13), object(2)\n",
      "memory usage: 1.6+ MB\n"
     ]
    }
   ],
   "source": [
    "# Crear UID único para el DataFrame completo\n",
    "df_join_pobre['UID'] = (\n",
    "    df_join_pobre['CODUSU'].astype(str) + '_' + \n",
    "    df_join_pobre['NRO_HOGAR'].astype(str) + '_' + \n",
    "    df_join_pobre['COMPONENTE'].astype(str)\n",
    ")   \n",
    "df_join_pobre.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f3e846b8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ESTADO\n",
      "3    7819\n",
      "1    5547\n",
      "2     664\n",
      "Name: count, dtype: int64\n",
      "V5\n",
      "2    10492\n",
      "1     3538\n",
      "Name: count, dtype: int64\n",
      "REGION\n",
      "43    4106\n",
      "40    3670\n",
      "1     1751\n",
      "41    1635\n",
      "42    1577\n",
      "44    1291\n",
      "Name: count, dtype: int64\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 14030 entries, 0 to 14029\n",
      "Data columns (total 15 columns):\n",
      " #   Column      Non-Null Count  Dtype \n",
      "---  ------      --------------  ----- \n",
      " 0   CODUSU      14030 non-null  object\n",
      " 1   NRO_HOGAR   14030 non-null  int64 \n",
      " 2   DECIFR      14030 non-null  int64 \n",
      " 3   REGION      14030 non-null  object\n",
      " 4   V5_01       14030 non-null  int64 \n",
      " 5   V5_02       14030 non-null  int64 \n",
      " 6   V5_03       14030 non-null  int64 \n",
      " 7   V5          14030 non-null  object\n",
      " 8   COMPONENTE  14030 non-null  int64 \n",
      " 9   ESTADO      14030 non-null  object\n",
      " 10  V5_01_M     14030 non-null  int64 \n",
      " 11  V5_02_M     14030 non-null  int64 \n",
      " 12  V5_03_M     14030 non-null  int64 \n",
      " 13  PONDERA     14030 non-null  int64 \n",
      " 14  UID         14030 non-null  object\n",
      "dtypes: int64(10), object(5)\n",
      "memory usage: 1.6+ MB\n"
     ]
    }
   ],
   "source": [
    "#chequeo previo a recodificar\n",
    "print(df_join_pobre['ESTADO'].value_counts())\n",
    "print(df_join_pobre['V5'].value_counts())\n",
    "print(df_join_pobre['REGION'].value_counts())\n",
    "\n",
    "# Recodificar variables (fusionar 1 y 2 como Activo; v5 con percibe/no-percibe)\n",
    "df_join_pobre['ESTADO'] = df_join_pobre['ESTADO'].replace({1: 'Activo', 2: 'Activo', 3: 'Inactivo'})\n",
    "df_join_pobre['V5'] = df_join_pobre['V5'].replace({1: 'Percibe', 2: 'No Percibe'})\n",
    "df_join_pobre['REGION'] = df_join_pobre['REGION'].replace({1: 'Gran Buenos Aires', 40: 'Noroeste', 41: 'Noreste', 42: 'Cuyo', 43: 'Pampeana', 44: 'Patagonia'})\n",
    "\n",
    "df_join_pobre.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8268254f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14030\n",
      "8225518\n",
      "14030.0\n"
     ]
    }
   ],
   "source": [
    "#ponderador casero\n",
    "n = len(df_join_pobre)\n",
    "N_t = df_join_pobre['PONDERA'].sum()\n",
    "ajuste = n / N_t\n",
    "df_join_pobre['PONDERA2'] = df_join_pobre['PONDERA'] * ajuste\n",
    "#verif ponderadores\n",
    "print(n)\n",
    "print(df_join_pobre['PONDERA'].sum())\n",
    "print(df_join_pobre['PONDERA2'].sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "15c68643",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lista para guardar todas las tablas (Nacional + Regiones)\n",
    "tablas_a_unir = []\n",
    "\n",
    "# --- 1. TABLA NACIONAL (TOTAL) ---\n",
    "\n",
    "# 1a. Calcular Absolutos Nacional\n",
    "tabla_nac_abs = pd.pivot_table(\n",
    "    df_join_pobre,\n",
    "    values='PONDERA2',\n",
    "    index='ESTADO',\n",
    "    columns='V5',\n",
    "    aggfunc='sum',\n",
    "    margins=True,\n",
    "    margins_name='Total',\n",
    "    fill_value=0 # Rellenar con 0 si hay cruces vacíos\n",
    ")\n",
    "\n",
    "# 1b. Calcular Porcentajes Nacional\n",
    "tabla_nac_pct = tabla_nac_abs.apply(lambda x: (x / x['Total']) * 100).round(2)\n",
    "\n",
    "# 1c. Añadir el nivel 'Tipo' al índice\n",
    "tabla_nac_abs['Tipo'] = 'Absoluto'\n",
    "tabla_nac_pct['Tipo'] = 'Porcentaje'\n",
    "\n",
    "# 1d. Apilar Abs y Pct\n",
    "tabla_nacional_final = pd.concat([tabla_nac_abs, tabla_nac_pct])\n",
    "tabla_nacional_final = tabla_nacional_final.set_index('Tipo', append=True)\n",
    "\n",
    "# 1e. Añadir a la lista, etiquetando esta tabla como REGION = 'Total'\n",
    "tablas_a_unir.append(\n",
    "    pd.concat([tabla_nacional_final], keys=['Total (Nacional)'], names=['REGION'])\n",
    ")\n",
    "\n",
    "\n",
    "# --- 2. TABLAS PARCIALES (POR REGION) ---\n",
    "\n",
    "regiones_ordenadas = sorted(df_join_pobre['REGION'].unique())\n",
    "\n",
    "for region_id in regiones_ordenadas:\n",
    "    df_region = df_join_pobre[df_join_pobre['REGION'] == region_id]\n",
    "    \n",
    "    if df_region.empty:\n",
    "        continue\n",
    "    \n",
    "    # 2a. Calcular Absolutos para la Región\n",
    "    tabla_reg_abs = pd.pivot_table(\n",
    "        df_region,\n",
    "        values='PONDERA2',\n",
    "        index='ESTADO',\n",
    "        columns='V5',\n",
    "        aggfunc='sum',\n",
    "        margins=True,\n",
    "        margins_name='Total',\n",
    "        fill_value=0\n",
    "    )\n",
    "    \n",
    "    # 2b. Calcular Porcentajes para la Región\n",
    "    tabla_reg_pct = tabla_reg_abs.apply(lambda x: (x / x['Total']) * 100).round(2)\n",
    "    \n",
    "    # 2c. Añadir el nivel 'Tipo'\n",
    "    tabla_reg_abs['Tipo'] = 'Absoluto'\n",
    "    tabla_reg_pct['Tipo'] = 'Porcentaje'\n",
    "    \n",
    "    # 2d. Apilar\n",
    "    tabla_region_final = pd.concat([tabla_reg_abs, tabla_reg_pct])\n",
    "    tabla_region_final = tabla_region_final.set_index('Tipo', append=True)\n",
    "    \n",
    "    # 2e. Añadir a la lista, etiquetando con el nombre de la Región\n",
    "    tablas_a_unir.append(\n",
    "        pd.concat([tabla_region_final], keys=[region_id], names=['REGION'])\n",
    "    )\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "17fd9d0b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generando reporte unificado con Chi-Cuadrado...\n",
      "¡Listo! Análisis completo guardado en 'analisis_completo_con_chi2.xlsx'\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# --- Función de Ayuda para Chi-Cuadrado ---\n",
    "# Esto crea un string con los resultados (Chi² y p-valor)\n",
    "# Y añade un (*) si es significativo.\n",
    "def get_chi2_results(abs_table):\n",
    "    \"\"\"Calcula Chi² y devuelve un string formateado.\"\"\"\n",
    "    \n",
    "    # Quitar márgenes 'Total' para el cálculo\n",
    "    table_no_totals = abs_table.iloc[:-1, :-1]\n",
    "    \n",
    "    if table_no_totals.empty:\n",
    "        return \"Datos insuficientes\"\n",
    "        \n",
    "    try:\n",
    "        chi2, p_valor, _, _ = chi2_contingency(table_no_totals)\n",
    "        \n",
    "        # Formatear el p-valor\n",
    "        p_str = f\"p={p_valor:.4f}\"\n",
    "        if p_valor < 0.05:\n",
    "            p_str += \" (*)\" # Marcador de significancia\n",
    "            \n",
    "        return f\"Chi²={chi2:.2f}; {p_str}\"\n",
    "        \n",
    "    except ValueError as e:\n",
    "        # Pasa si una fila/columna es todo 0\n",
    "        return \"Cálculo no válido\"\n",
    "# --- Fin de la Función de Ayuda ---\n",
    "\n",
    "\n",
    "print(\"Generando reporte unificado con Chi-Cuadrado...\")\n",
    "\n",
    "# --- Preparación para el Excel ---\n",
    "output_filename = 'analisis_completo_con_chi2.xlsx'\n",
    "sheet_name = 'Analisis_Completo'\n",
    "\n",
    "# Calcular dónde irá la columna de Chi²\n",
    "# 3 niveles de índice (REGION, ESTADO, Tipo) \n",
    "index_cols_count = 3\n",
    "# Columnas de datos (V5) + 1 (Total)\n",
    "data_cols_count = df_join_pobre['V5'].nunique() + 1\n",
    "# La columna de Chi² irá después de los índices y los datos + 1 columna de espacio\n",
    "col_inicio_chi2 = index_cols_count + data_cols_count + 1\n",
    "\n",
    "# Fila actual donde escribirá Excel\n",
    "fila_actual = 0\n",
    "\n",
    "with pd.ExcelWriter(output_filename, engine='xlsxwriter') as writer:\n",
    "    \n",
    "    # Escribir el título de la columna Chi²\n",
    "    pd.DataFrame(['Análisis Chi² (χ²)']).to_excel(\n",
    "        writer, sheet_name=sheet_name, \n",
    "        startrow=fila_actual, startcol=col_inicio_chi2, \n",
    "        header=False, index=False\n",
    "    )\n",
    "    fila_actual += 2 # Dejar espacio\n",
    "\n",
    "    \n",
    "    # --- 1. TABLA NACIONAL (TOTAL) ---\n",
    "    \n",
    "    # 1a. Calcular Absolutos Nacional\n",
    "    tabla_nac_abs = pd.pivot_table(\n",
    "        df_join_pobre, values='PONDERA2', index='ESTADO', columns='V5',\n",
    "        aggfunc='sum', margins=True, margins_name='Total', fill_value=0\n",
    "    )\n",
    "    # 1b. Calcular Porcentajes Nacional\n",
    "    tabla_nac_pct = tabla_nac_abs.apply(lambda x: (x / x['Total']) * 100).round(2)\n",
    "    \n",
    "    # 1c. Calcular Chi-Cuadrado Nacional\n",
    "    chi2_nac_str = get_chi2_results(tabla_nac_abs)\n",
    "    \n",
    "    # 1d. Apilar Abs/Pct y añadir índice 'Tipo'\n",
    "    tabla_nac_abs['Tipo'] = 'Absoluto'\n",
    "    tabla_nac_pct['Tipo'] = 'Porcentaje'\n",
    "    tabla_nacional_final = pd.concat([tabla_nac_abs, tabla_nac_pct]).set_index('Tipo', append=True)\n",
    "    \n",
    "    # 1e. Añadir índice 'REGION' y ordenar\n",
    "    tabla_nacional_listo = pd.concat([tabla_nacional_final], keys=['Total (Nacional)'], names=['REGION'])\n",
    "    tabla_nacional_listo = tabla_nacional_listo.sort_index()\n",
    "    \n",
    "    # 1f. Escribir la tabla principal a Excel\n",
    "    tabla_nacional_listo.to_excel(\n",
    "        writer, sheet_name=sheet_name, \n",
    "        startrow=fila_actual\n",
    "    )\n",
    "    \n",
    "    # 1g. Escribir el resultado de Chi² alineado verticalmente\n",
    "    fila_chi2 = fila_actual + (tabla_nacional_listo.shape[0] // 2) # Centrado\n",
    "    pd.DataFrame([chi2_nac_str]).to_excel(\n",
    "        writer, sheet_name=sheet_name, \n",
    "        startrow=fila_chi2, startcol=col_inicio_chi2, \n",
    "        header=False, index=False\n",
    "    )\n",
    "    \n",
    "    # 1h. Actualizar la posición de la fila para la siguiente tabla\n",
    "    fila_actual += tabla_nacional_listo.shape[0] + 2 # +2 para espacio\n",
    "\n",
    "    \n",
    "    # --- 2. TABLAS PARCIALES (POR REGION) ---\n",
    "    \n",
    "    regiones_ordenadas = sorted(df_join_pobre['REGION'].unique())\n",
    "    \n",
    "    for region_id in regiones_ordenadas:\n",
    "        df_region = df_join_pobre[df_join_pobre['REGION'] == region_id]\n",
    "        if df_region.empty:\n",
    "            continue\n",
    "        \n",
    "        # 2a. Calcular Absolutos\n",
    "        tabla_reg_abs = pd.pivot_table(\n",
    "            df_region, values='PONDERA2', index='ESTADO', columns='V5',\n",
    "            aggfunc='sum', margins=True, margins_name='Total', fill_value=0\n",
    "        )\n",
    "        # 2b. Calcular Porcentajes\n",
    "        tabla_reg_pct = tabla_reg_abs.apply(lambda x: (x / x['Total']) * 100).round(2)\n",
    "        \n",
    "        # 2c. Calcular Chi-Cuadrado\n",
    "        chi2_reg_str = get_chi2_results(tabla_reg_abs)\n",
    "        \n",
    "        # 2d. Apilar Abs/Pct y añadir índice 'Tipo'\n",
    "        tabla_reg_abs['Tipo'] = 'Absoluto'\n",
    "        tabla_reg_pct['Tipo'] = 'Porcentaje'\n",
    "        tabla_region_final = pd.concat([tabla_reg_abs, tabla_reg_pct]).set_index('Tipo', append=True)\n",
    "        \n",
    "        # 2e. Añadir índice 'REGION' y ordenar\n",
    "        tabla_region_listo = pd.concat([tabla_region_final], keys=[region_id], names=['REGION'])\n",
    "        tabla_region_listo = tabla_region_listo.sort_index()\n",
    "        \n",
    "        # 2f. Escribir la tabla a Excel (sin encabezado esta vez)\n",
    "        tabla_region_listo.to_excel(\n",
    "            writer, sheet_name=sheet_name, \n",
    "            startrow=fila_actual, \n",
    "            header=False # El encabezado ya se escribió con la tabla nacional\n",
    "        )\n",
    "        \n",
    "        # 2g. Escribir el resultado de Chi² alineado\n",
    "        fila_chi2 = fila_actual + (tabla_region_listo.shape[0] // 2) # Centrado\n",
    "        pd.DataFrame([chi2_reg_str]).to_excel(\n",
    "            writer, sheet_name=sheet_name, \n",
    "            startrow=fila_chi2, startcol=col_inicio_chi2, \n",
    "            header=False, index=False\n",
    "        )\n",
    "        \n",
    "        # 2h. Actualizar la fila\n",
    "        fila_actual += tabla_region_listo.shape[0] + 2 # +2 para espacio\n",
    "\n",
    "print(f\"¡Listo! Análisis completo guardado en '{output_filename}'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f9e273fe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculando Regresión Logística Nacional...\n",
      "Calculando Regresiones Logísticas por Región...\n",
      "  > Región Cuyo calculada.\n",
      "  > Región Gran Buenos Aires calculada.\n",
      "  > Región Noreste calculada.\n",
      "  > Región Noroeste calculada.\n",
      "  > Región Pampeana calculada.\n",
      "  > Región Patagonia calculada.\n",
      "\n",
      "==================================================\n",
      "RESULTADOS DE LA REGRESIÓN LOGÍSTICA\n",
      "==================================================\n",
      "                   Beta (Intercept)  Beta (V5[T.Percibe])  P-Valor (Intercept)  P-Valor (V5[T.Percibe])  Nagelkerke R²  N (Suma Ponderador)\n",
      "Modelo                                                                                                                                     \n",
      "Total (Nacional)          -0.207465              0.074837         7.590749e-25                 0.044830       0.000287                14030\n",
      "Cuyo                      -0.122802             -0.010573         9.480476e-02                 0.941435       0.000006                 1577\n",
      "Gran Buenos Aires         -0.222493              0.174601         2.757961e-14                 0.001145       0.006019                 1751\n",
      "Noreste                   -0.194527             -0.264815         1.872855e-02                 0.071906       0.003844                 1635\n",
      "Noroeste                  -0.147655              0.016602         9.854487e-03                 0.870320       0.000007                 3670\n",
      "Pampeana                  -0.232124              0.050332         2.583843e-08                 0.525128       0.000098                 4106\n",
      "Patagonia                 -0.257149             -0.221302         2.225244e-02                 0.347180       0.001926                 1291\n",
      "\n",
      "--- Fin del Análisis de Regresión ---\n"
     ]
    }
   ],
   "source": [
    "# statsmodels necesita que la variable dependiente (Y) sea numérica (0 o 1).\n",
    "# Vamos a crear 'ESTADO_BIN'. Asumiremos 'Activo' = 1 y 'Inactivo' = 0.\n",
    "df_regresion = df_join_pobre.copy()\n",
    "df_regresion['ESTADO_BIN'] = df_regresion['ESTADO'].apply(lambda x: 1 if x == 'Activo' else 0)\n",
    "\n",
    "# La fórmula. statsmodels manejará 'V5' (Percibe/No Percibe) como una variable dummy.\n",
    "# Automáticamente usará una categoría (alfabéticamente, 'No Percibe') como base.\n",
    "formula = 'ESTADO_BIN ~ V5'\n",
    "\n",
    "# --- PASO 2: Función de Ayuda para R² de Nagelkerke ---\n",
    "# statsmodels por defecto da el R² de McFadden, así que calculamos el de Nagelkerke.\n",
    "def get_nagelkerke_r2(results):\n",
    "    \"\"\"Calcula el Pseudo R² de Nagelkerke a partir de un resultado de statsmodels.\"\"\"\n",
    "    try:\n",
    "        llf = results.llf  # Log-likelihood del modelo completo\n",
    "        lln = results.llnull # Log-likelihood del modelo nulo (solo intercepto)\n",
    "        n = results.nobs   # Número de observaciones (suma de ponderadores)\n",
    "        \n",
    "        # Calcular R² de Cox & Snell\n",
    "        r2_cs = 1 - (np.exp(lln - llf))**(2/n)\n",
    "        \n",
    "        # Calcular el R² máximo\n",
    "        r2_max_nagel = 1 - (np.exp(lln))**(2/n)\n",
    "        \n",
    "        if r2_max_nagel == 0:\n",
    "            return 0.0\n",
    "            \n",
    "        return r2_cs / r2_max_nagel\n",
    "    except Exception:\n",
    "        return np.nan\n",
    "\n",
    "# --- PASO 3: Correr modelos y guardar resultados ---\n",
    "results_list = []\n",
    "\n",
    "# Corremos primero el modelo Nacional\n",
    "print(\"Calculando Regresión Logística Nacional...\")\n",
    "try:\n",
    "    df_nat = df_regresion\n",
    "    pesos_nat = df_nat['PONDERA2']\n",
    "    \n",
    "    # Usamos GLM (Modelo Lineal Generalizado) con familia Binomial (logística)\n",
    "    # y 'freq_weights' para aplicar el ponderador PONDERA2.\n",
    "    modelo_nat = smf.glm(formula=formula, \n",
    "                         data=df_nat, \n",
    "                         family=sm.families.Binomial(), \n",
    "                         freq_weights=pesos_nat)\n",
    "    results_nat = modelo_nat.fit()\n",
    "    \n",
    "    # Extraer resultados\n",
    "    coefs_nat = results_nat.params\n",
    "    pvals_nat = results_nat.pvalues\n",
    "    nagel_nat = get_nagelkerke_r2(results_nat)\n",
    "    \n",
    "    # Detectar el nombre de la columna V5 (ej. \"V5[T.Percibe]\")\n",
    "    v5_col_name = [col for col in coefs_nat.index if 'V5[' in col][0]\n",
    "    \n",
    "    results_list.append({\n",
    "        'Modelo': 'Total (Nacional)',\n",
    "        'Beta (Intercept)': coefs_nat['Intercept'],\n",
    "        f'Beta ({v5_col_name})': coefs_nat[v5_col_name],\n",
    "        'P-Valor (Intercept)': pvals_nat['Intercept'],\n",
    "        f'P-Valor ({v5_col_name})': pvals_nat[v5_col_name],\n",
    "        'Nagelkerke R²': nagel_nat,\n",
    "        'N (Suma Ponderador)': results_nat.nobs\n",
    "    })\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"Error al calcular modelo nacional: {e}\")\n",
    "\n",
    "# Ahora iteramos y corremos el modelo para CADA REGIÓN\n",
    "print(\"Calculando Regresiones Logísticas por Región...\")\n",
    "regiones_ordenadas = sorted(df_regresion['REGION'].unique())\n",
    "\n",
    "for region_id in regiones_ordenadas:\n",
    "    df_region = df_regresion[df_regresion['REGION'] == region_id]\n",
    "    \n",
    "    # Asegurarnos de que hay suficientes datos y variabilidad para correr el modelo\n",
    "    if df_region.empty or df_region['V5'].nunique() < 2 or df_region['ESTADO_BIN'].nunique() < 2:\n",
    "        print(f\"  > Omitiendo Región {region_id}: datos insuficientes o sin variabilidad.\")\n",
    "        continue\n",
    "        \n",
    "    try:\n",
    "        pesos_reg = df_region['PONDERA2']\n",
    "        modelo_reg = smf.glm(formula=formula, \n",
    "                             data=df_region, \n",
    "                             family=sm.families.Binomial(), \n",
    "                             freq_weights=pesos_reg)\n",
    "        results_reg = modelo_reg.fit()\n",
    "        \n",
    "        # Extraer resultados\n",
    "        coefs_reg = results_reg.params\n",
    "        pvals_reg = results_reg.pvalues\n",
    "        nagel_reg = get_nagelkerke_r2(results_reg)\n",
    "        \n",
    "        v5_col_name_reg = [col for col in coefs_reg.index if 'V5[' in col][0]\n",
    "        \n",
    "        results_list.append({\n",
    "            'Modelo': region_id,\n",
    "            'Beta (Intercept)': coefs_reg['Intercept'],\n",
    "            f'Beta ({v5_col_name})': coefs_reg[v5_col_name_reg],\n",
    "            'P-Valor (Intercept)': pvals_reg['Intercept'],\n",
    "            f'P-Valor ({v5_col_name})': pvals_reg[v5_col_name_reg],\n",
    "            'Nagelkerke R²': nagel_reg,\n",
    "            'N (Suma Ponderador)': results_reg.nobs\n",
    "        })\n",
    "        print(f\"  > Región {region_id} calculada.\")\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"  > Error al calcular modelo para {region_id}: {e}\")\n",
    "\n",
    "# --- PASO 4: Presentar los resultados en una tabla ---\n",
    "if results_list:\n",
    "    df_summary = pd.DataFrame(results_list)\n",
    "    df_summary = df_summary.set_index('Modelo')\n",
    "    \n",
    "    print(\"\\n\" + \"=\"*50)\n",
    "    print(\"RESULTADOS DE LA REGRESIÓN LOGÍSTICA\")\n",
    "    print(\"=\"*50)\n",
    "    # Usamos .to_string() para asegurarnos de que se impriman todas las columnas\n",
    "    print(df_summary.to_string())\n",
    "else:\n",
    "    print(\"No se pudieron generar resultados de regresión.\")\n",
    "\n",
    "print(\"\\n--- Fin del Análisis de Regresión ---\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv (3.13.1)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "1b74e314",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from pandas.plotting import table\n",
    "import numpy as np  \n",
    "import matplotlib.pyplot as plt\n",
    "import openpyxl\n",
    "from IPython.display import HTML\n",
    "import pingouin as pg\n",
    "import os\n",
    "from scipy.stats import chi2_contingency\n",
    "import statsmodels.api as sm\n",
    "import statsmodels.formula.api as smf\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3e67e32a",
   "metadata": {},
   "outputs": [],
   "source": [
    "xl_usu = 'usu_individual_T125.xlsx'  \n",
    "dfusu = pd.read_excel(xl_usu)\n",
    "dfusu = dfusu.loc[:, ['CODUSU','NRO_HOGAR','COMPONENTE', 'ESTADO','V5_01_M','V5_02_M','V5_03_M','PONDERA']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "96a45606",
   "metadata": {},
   "outputs": [],
   "source": [
    "xl_hog = 'usu_hogar_T125.xlsx'  \n",
    "dfhog = pd.read_excel(xl_hog)\n",
    "dfhog = dfhog.loc[:, ['CODUSU','NRO_HOGAR','DECIFR','REGION','V5_01','V5_02','V5_03']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5ad8a59b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CODUSU</th>\n",
       "      <th>NRO_HOGAR</th>\n",
       "      <th>DECIFR</th>\n",
       "      <th>REGION</th>\n",
       "      <th>V5_01</th>\n",
       "      <th>V5_02</th>\n",
       "      <th>V5_03</th>\n",
       "      <th>V5</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>TQRMNOQVSHKOLNCDEGGFB00858441</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>42</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>TQSMNORTSHMOLTCDEGGFB00877605</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>42</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>TQRMNOQQXHMMMLCDEGGFB00877606</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>42</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>TQRMNOTTWHMMLOCDEFIAH00877819</td>\n",
       "      <td>1</td>\n",
       "      <td>12</td>\n",
       "      <td>43</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>TQRMNORQQHLMKOCDEHIBB00853810</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>40</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                          CODUSU  NRO_HOGAR  DECIFR  REGION  V5_01  V5_02  \\\n",
       "0  TQRMNOQVSHKOLNCDEGGFB00858441          1       1      42      2      2   \n",
       "1  TQSMNORTSHMOLTCDEGGFB00877605          1       6      42      2      2   \n",
       "2  TQRMNOQQXHMMMLCDEGGFB00877606          1       4      42      2      2   \n",
       "3  TQRMNOTTWHMMLOCDEFIAH00877819          1      12      43      2      2   \n",
       "4  TQRMNORQQHLMKOCDEHIBB00853810          2       1      40      2      2   \n",
       "\n",
       "   V5_03  V5  \n",
       "0      2   2  \n",
       "1      2   2  \n",
       "2      2   2  \n",
       "3      2   2  \n",
       "4      2   2  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# V5 = 1 si ALGUNA variable es 1, 2 solo si TODAS son 2\n",
    "dfhog['V5'] = 2  # Inicializar con 2 (asumiendo que todas son 2)\n",
    "\n",
    "# Si ALGUNA variable es 1, entonces V5 = 1\n",
    "mask_alguna_1 = (dfhog['V5_01'] == 1) | (dfhog['V5_02'] == 1) | (dfhog['V5_03'] == 1)\n",
    "dfhog.loc[mask_alguna_1, 'V5'] = 1\n",
    "\n",
    "#print(dfhog['V5'].value_counts().sort_index())\n",
    "dfhog.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "cb73e748",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DECIFR\n",
      "1    1457\n",
      "4    1350\n",
      "2    1333\n",
      "5    1287\n",
      "3    1273\n",
      "Name: count, dtype: int64\n",
      "ESTADO\n",
      "1    20076\n",
      "3    18866\n",
      "2     1381\n",
      "Name: count, dtype: int64\n",
      "---------------------------------------------------\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 6700 entries, 0 to 15979\n",
      "Data columns (total 8 columns):\n",
      " #   Column     Non-Null Count  Dtype \n",
      "---  ------     --------------  ----- \n",
      " 0   CODUSU     6700 non-null   object\n",
      " 1   NRO_HOGAR  6700 non-null   int64 \n",
      " 2   DECIFR     6700 non-null   int64 \n",
      " 3   REGION     6700 non-null   int64 \n",
      " 4   V5_01      6700 non-null   int64 \n",
      " 5   V5_02      6700 non-null   int64 \n",
      " 6   V5_03      6700 non-null   int64 \n",
      " 7   V5         6700 non-null   int64 \n",
      "dtypes: int64(7), object(1)\n",
      "memory usage: 471.1+ KB\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 40323 entries, 0 to 45424\n",
      "Data columns (total 8 columns):\n",
      " #   Column      Non-Null Count  Dtype \n",
      "---  ------      --------------  ----- \n",
      " 0   CODUSU      40323 non-null  object\n",
      " 1   NRO_HOGAR   40323 non-null  int64 \n",
      " 2   COMPONENTE  40323 non-null  int64 \n",
      " 3   ESTADO      40323 non-null  int64 \n",
      " 4   V5_01_M     40323 non-null  int64 \n",
      " 5   V5_02_M     40323 non-null  int64 \n",
      " 6   V5_03_M     40323 non-null  int64 \n",
      " 7   PONDERA     40323 non-null  int64 \n",
      "dtypes: int64(7), object(1)\n",
      "memory usage: 2.8+ MB\n"
     ]
    }
   ],
   "source": [
    "#hogares: filtrar 50% m√°s pobre (0 y 12)\n",
    "\n",
    "dfhog_pobre = dfhog[dfhog['DECIFR'].isin([1, 2, 3, 4, 5])]\n",
    "print(dfhog_pobre['DECIFR'].value_counts())\n",
    "\n",
    "#persona: filtrar por Estado 1 (ocupado), 2 (desocupado) y 3 (inactivo)\n",
    "dfusu = dfusu[dfusu['ESTADO'].isin([1, 2, 3])]\n",
    "print(dfusu['ESTADO'].value_counts())\n",
    "\n",
    "print(\"---------------------------------------------------\")\n",
    "dfhog_pobre.info()\n",
    "dfusu.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f4c0d12c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 14030 entries, 0 to 14029\n",
      "Data columns (total 14 columns):\n",
      " #   Column      Non-Null Count  Dtype \n",
      "---  ------      --------------  ----- \n",
      " 0   CODUSU      14030 non-null  object\n",
      " 1   NRO_HOGAR   14030 non-null  int64 \n",
      " 2   DECIFR      14030 non-null  int64 \n",
      " 3   REGION      14030 non-null  int64 \n",
      " 4   V5_01       14030 non-null  int64 \n",
      " 5   V5_02       14030 non-null  int64 \n",
      " 6   V5_03       14030 non-null  int64 \n",
      " 7   V5          14030 non-null  int64 \n",
      " 8   COMPONENTE  14030 non-null  int64 \n",
      " 9   ESTADO      14030 non-null  int64 \n",
      " 10  V5_01_M     14030 non-null  int64 \n",
      " 11  V5_02_M     14030 non-null  int64 \n",
      " 12  V5_03_M     14030 non-null  int64 \n",
      " 13  PONDERA     14030 non-null  int64 \n",
      "dtypes: int64(13), object(1)\n",
      "memory usage: 1.5+ MB\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CODUSU</th>\n",
       "      <th>NRO_HOGAR</th>\n",
       "      <th>DECIFR</th>\n",
       "      <th>REGION</th>\n",
       "      <th>V5_01</th>\n",
       "      <th>V5_02</th>\n",
       "      <th>V5_03</th>\n",
       "      <th>V5</th>\n",
       "      <th>COMPONENTE</th>\n",
       "      <th>ESTADO</th>\n",
       "      <th>V5_01_M</th>\n",
       "      <th>V5_02_M</th>\n",
       "      <th>V5_03_M</th>\n",
       "      <th>PONDERA</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>TQRMNOQVSHKOLNCDEGGFB00858441</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>42</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>526</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>TQRMNOQVSHKOLNCDEGGFB00858441</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>42</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>526</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>TQRMNOQQXHMMMLCDEGGFB00877606</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>42</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>446</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>TQRMNOQQXHMMMLCDEGGFB00877606</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>42</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>446</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>TQRMNORQQHLMKOCDEHIBB00853810</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>40</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>132</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>TQRMNOTPYHMOLQCDEFMDB00877823</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>43</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>199</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>TQRMNOTPYHMOLQCDEFMDB00877823</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>43</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>199</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>TQRMNORVVHLLLPCDEFMDB00852190</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>43</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>146</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>TQRMNOQTTHKMKSCDEFMDB00857883</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>43</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>234</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>TQRMNOPXWHMOKSCDEOJAH00877825</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>44</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>113</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>TQRMNORPXHLLKRCDEOJAH00856304</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>44</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>92</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>TQRMNORPXHLLKRCDEOJAH00856304</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>44</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>92</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>TQRMNORPXHLLKRCDEOJAH00856304</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>44</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>92</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>TQRMNOPWTHLOKTCDEOJAH00856786</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>44</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>46</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>TQSMNOPSYHKMMLCDEFKID00861533</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>43</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>720</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>TQSMNOPSYHKMMLCDEFKID00861533</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>43</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>60000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>720</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>TQRMNOSVSHKMMLCDEFKID00861389</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>43</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>586</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>TQRMNOSVSHKMMLCDEFKID00861389</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>43</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>586</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>TQRMNOSUXHLLLUCDEFKID00861457</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>43</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1770</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>TQRMNOPSXHLMLMCDEIJAH00855495</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3440</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                           CODUSU  NRO_HOGAR  DECIFR  REGION  V5_01  V5_02  \\\n",
       "0   TQRMNOQVSHKOLNCDEGGFB00858441          1       1      42      2      2   \n",
       "1   TQRMNOQVSHKOLNCDEGGFB00858441          1       1      42      2      2   \n",
       "2   TQRMNOQQXHMMMLCDEGGFB00877606          1       4      42      2      2   \n",
       "3   TQRMNOQQXHMMMLCDEGGFB00877606          1       4      42      2      2   \n",
       "4   TQRMNORQQHLMKOCDEHIBB00853810          2       1      40      2      2   \n",
       "5   TQRMNOTPYHMOLQCDEFMDB00877823          1       5      43      2      2   \n",
       "6   TQRMNOTPYHMOLQCDEFMDB00877823          1       5      43      2      2   \n",
       "7   TQRMNORVVHLLLPCDEFMDB00852190          1       3      43      2      2   \n",
       "8   TQRMNOQTTHKMKSCDEFMDB00857883          1       3      43      2      2   \n",
       "9   TQRMNOPXWHMOKSCDEOJAH00877825          1       3      44      2      2   \n",
       "10  TQRMNORPXHLLKRCDEOJAH00856304          1       5      44      2      2   \n",
       "11  TQRMNORPXHLLKRCDEOJAH00856304          1       5      44      2      2   \n",
       "12  TQRMNORPXHLLKRCDEOJAH00856304          1       5      44      2      2   \n",
       "13  TQRMNOPWTHLOKTCDEOJAH00856786          1       2      44      2      2   \n",
       "14  TQSMNOPSYHKMMLCDEFKID00861533          1       4      43      1      2   \n",
       "15  TQSMNOPSYHKMMLCDEFKID00861533          1       4      43      1      2   \n",
       "16  TQRMNOSVSHKMMLCDEFKID00861389          1       3      43      2      2   \n",
       "17  TQRMNOSVSHKMMLCDEFKID00861389          1       3      43      2      2   \n",
       "18  TQRMNOSUXHLLLUCDEFKID00861457          1       1      43      2      2   \n",
       "19  TQRMNOPSXHLMLMCDEIJAH00855495          1       3       1      2      2   \n",
       "\n",
       "    V5_03  V5  COMPONENTE  ESTADO  V5_01_M  V5_02_M  V5_03_M  PONDERA  \n",
       "0       2   2           1       1        0        0        0      526  \n",
       "1       2   2           2       3        0        0        0      526  \n",
       "2       2   2           1       3        0        0        0      446  \n",
       "3       2   2           2       3        0        0        0      446  \n",
       "4       2   2           1       3        0        0        0      132  \n",
       "5       2   2           1       1        0        0        0      199  \n",
       "6       2   2           2       1        0        0        0      199  \n",
       "7       2   2           1       3        0        0        0      146  \n",
       "8       2   2           1       1        0        0        0      234  \n",
       "9       2   2           1       1        0        0        0      113  \n",
       "10      2   2           1       2        0        0        0       92  \n",
       "11      2   2           2       3        0        0        0       92  \n",
       "12      2   2           3       3        0        0        0       92  \n",
       "13      2   2           1       3        0        0        0       46  \n",
       "14      2   1           1       1        0        0        0      720  \n",
       "15      2   1           2       1    60000        0        0      720  \n",
       "16      2   2           1       3        0        0        0      586  \n",
       "17      2   2           2       3        0        0        0      586  \n",
       "18      2   2           1       3        0        0        0     1770  \n",
       "19      2   2           1       3        0        0        0     3440  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Juntar tablas (left hogares pobres, right individuos)\n",
    "df_join_pobre = dfhog_pobre.merge(dfusu, how='left', on=['CODUSU', 'NRO_HOGAR'])\n",
    "df_join_pobre.info()\n",
    "df_join_pobre.head(20)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "45ada7d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 14030 entries, 0 to 14029\n",
      "Data columns (total 15 columns):\n",
      " #   Column      Non-Null Count  Dtype \n",
      "---  ------      --------------  ----- \n",
      " 0   CODUSU      14030 non-null  object\n",
      " 1   NRO_HOGAR   14030 non-null  int64 \n",
      " 2   DECIFR      14030 non-null  int64 \n",
      " 3   REGION      14030 non-null  int64 \n",
      " 4   V5_01       14030 non-null  int64 \n",
      " 5   V5_02       14030 non-null  int64 \n",
      " 6   V5_03       14030 non-null  int64 \n",
      " 7   V5          14030 non-null  int64 \n",
      " 8   COMPONENTE  14030 non-null  int64 \n",
      " 9   ESTADO      14030 non-null  int64 \n",
      " 10  V5_01_M     14030 non-null  int64 \n",
      " 11  V5_02_M     14030 non-null  int64 \n",
      " 12  V5_03_M     14030 non-null  int64 \n",
      " 13  PONDERA     14030 non-null  int64 \n",
      " 14  UID         14030 non-null  object\n",
      "dtypes: int64(13), object(2)\n",
      "memory usage: 1.6+ MB\n"
     ]
    }
   ],
   "source": [
    "# Crear UID √∫nico para el DataFrame completo\n",
    "df_join_pobre['UID'] = (\n",
    "    df_join_pobre['CODUSU'].astype(str) + '_' + \n",
    "    df_join_pobre['NRO_HOGAR'].astype(str) + '_' + \n",
    "    df_join_pobre['COMPONENTE'].astype(str)\n",
    ")   \n",
    "df_join_pobre.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f3e846b8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ESTADO\n",
      "3    7819\n",
      "1    5547\n",
      "2     664\n",
      "Name: count, dtype: int64\n",
      "V5\n",
      "2    10492\n",
      "1     3538\n",
      "Name: count, dtype: int64\n",
      "REGION\n",
      "43    4106\n",
      "40    3670\n",
      "1     1751\n",
      "41    1635\n",
      "42    1577\n",
      "44    1291\n",
      "Name: count, dtype: int64\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 14030 entries, 0 to 14029\n",
      "Data columns (total 15 columns):\n",
      " #   Column      Non-Null Count  Dtype \n",
      "---  ------      --------------  ----- \n",
      " 0   CODUSU      14030 non-null  object\n",
      " 1   NRO_HOGAR   14030 non-null  int64 \n",
      " 2   DECIFR      14030 non-null  int64 \n",
      " 3   REGION      14030 non-null  object\n",
      " 4   V5_01       14030 non-null  int64 \n",
      " 5   V5_02       14030 non-null  int64 \n",
      " 6   V5_03       14030 non-null  int64 \n",
      " 7   V5          14030 non-null  object\n",
      " 8   COMPONENTE  14030 non-null  int64 \n",
      " 9   ESTADO      14030 non-null  object\n",
      " 10  V5_01_M     14030 non-null  int64 \n",
      " 11  V5_02_M     14030 non-null  int64 \n",
      " 12  V5_03_M     14030 non-null  int64 \n",
      " 13  PONDERA     14030 non-null  int64 \n",
      " 14  UID         14030 non-null  object\n",
      "dtypes: int64(10), object(5)\n",
      "memory usage: 1.6+ MB\n"
     ]
    }
   ],
   "source": [
    "#chequeo previo a recodificar\n",
    "print(df_join_pobre['ESTADO'].value_counts())\n",
    "print(df_join_pobre['V5'].value_counts())\n",
    "print(df_join_pobre['REGION'].value_counts())\n",
    "\n",
    "# Recodificar variables (fusionar 1 y 2 como Activo; v5 con percibe/no-percibe)\n",
    "df_join_pobre['ESTADO'] = df_join_pobre['ESTADO'].replace({1: 'Activo', 2: 'Activo', 3: 'Inactivo'})\n",
    "df_join_pobre['V5'] = df_join_pobre['V5'].replace({1: 'Percibe', 2: 'No Percibe'})\n",
    "df_join_pobre['REGION'] = df_join_pobre['REGION'].replace({1: 'Gran Buenos Aires', 40: 'Noroeste', 41: 'Noreste', 42: 'Cuyo', 43: 'Pampeana', 44: 'Patagonia'})\n",
    "\n",
    "df_join_pobre.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8268254f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14030\n",
      "8225518\n",
      "14030.0\n"
     ]
    }
   ],
   "source": [
    "#ponderador casero\n",
    "n = len(df_join_pobre)\n",
    "N_t = df_join_pobre['PONDERA'].sum()\n",
    "ajuste = n / N_t\n",
    "df_join_pobre['PONDERA2'] = df_join_pobre['PONDERA'] * ajuste\n",
    "#verif ponderadores\n",
    "print(n)\n",
    "print(df_join_pobre['PONDERA'].sum())\n",
    "print(df_join_pobre['PONDERA2'].sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "15c68643",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lista para guardar todas las tablas (Nacional + Regiones)\n",
    "tablas_a_unir = []\n",
    "\n",
    "# --- 1. TABLA NACIONAL (TOTAL) ---\n",
    "\n",
    "# 1a. Calcular Absolutos Nacional\n",
    "tabla_nac_abs = pd.pivot_table(\n",
    "    df_join_pobre,\n",
    "    values='PONDERA2',\n",
    "    index='ESTADO',\n",
    "    columns='V5',\n",
    "    aggfunc='sum',\n",
    "    margins=True,\n",
    "    margins_name='Total',\n",
    "    fill_value=0 # Rellenar con 0 si hay cruces vac√≠os\n",
    ")\n",
    "\n",
    "# 1b. Calcular Porcentajes Nacional\n",
    "tabla_nac_pct = tabla_nac_abs.apply(lambda x: (x / x['Total']) * 100).round(2)\n",
    "\n",
    "# 1c. A√±adir el nivel 'Tipo' al √≠ndice\n",
    "tabla_nac_abs['Tipo'] = 'Absoluto'\n",
    "tabla_nac_pct['Tipo'] = 'Porcentaje'\n",
    "\n",
    "# 1d. Apilar Abs y Pct\n",
    "tabla_nacional_final = pd.concat([tabla_nac_abs, tabla_nac_pct])\n",
    "tabla_nacional_final = tabla_nacional_final.set_index('Tipo', append=True)\n",
    "\n",
    "# 1e. A√±adir a la lista, etiquetando esta tabla como REGION = 'Total'\n",
    "tablas_a_unir.append(\n",
    "    pd.concat([tabla_nacional_final], keys=['Total (Nacional)'], names=['REGION'])\n",
    ")\n",
    "\n",
    "\n",
    "# --- 2. TABLAS PARCIALES (POR REGION) ---\n",
    "\n",
    "regiones_ordenadas = sorted(df_join_pobre['REGION'].unique())\n",
    "\n",
    "for region_id in regiones_ordenadas:\n",
    "    df_region = df_join_pobre[df_join_pobre['REGION'] == region_id]\n",
    "    \n",
    "    if df_region.empty:\n",
    "        continue\n",
    "    \n",
    "    # 2a. Calcular Absolutos para la Regi√≥n\n",
    "    tabla_reg_abs = pd.pivot_table(\n",
    "        df_region,\n",
    "        values='PONDERA2',\n",
    "        index='ESTADO',\n",
    "        columns='V5',\n",
    "        aggfunc='sum',\n",
    "        margins=True,\n",
    "        margins_name='Total',\n",
    "        fill_value=0\n",
    "    )\n",
    "    \n",
    "    # 2b. Calcular Porcentajes para la Regi√≥n\n",
    "    tabla_reg_pct = tabla_reg_abs.apply(lambda x: (x / x['Total']) * 100).round(2)\n",
    "    \n",
    "    # 2c. A√±adir el nivel 'Tipo'\n",
    "    tabla_reg_abs['Tipo'] = 'Absoluto'\n",
    "    tabla_reg_pct['Tipo'] = 'Porcentaje'\n",
    "    \n",
    "    # 2d. Apilar\n",
    "    tabla_region_final = pd.concat([tabla_reg_abs, tabla_reg_pct])\n",
    "    tabla_region_final = tabla_region_final.set_index('Tipo', append=True)\n",
    "    \n",
    "    # 2e. A√±adir a la lista, etiquetando con el nombre de la Regi√≥n\n",
    "    tablas_a_unir.append(\n",
    "        pd.concat([tabla_region_final], keys=[region_id], names=['REGION'])\n",
    "    )\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "17fd9d0b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generando reporte unificado con Chi-Cuadrado...\n",
      "¬°Listo! An√°lisis completo guardado en 'analisis_completo_con_chi2.xlsx'\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# --- Funci√≥n de Ayuda para Chi-Cuadrado ---\n",
    "# Esto crea un string con los resultados (Chi¬≤ y p-valor)\n",
    "# Y a√±ade un (*) si es significativo.\n",
    "def get_chi2_results(abs_table):\n",
    "    \"\"\"Calcula Chi¬≤ y devuelve un string formateado.\"\"\"\n",
    "    \n",
    "    # Quitar m√°rgenes 'Total' para el c√°lculo\n",
    "    table_no_totals = abs_table.iloc[:-1, :-1]\n",
    "    \n",
    "    if table_no_totals.empty:\n",
    "        return \"Datos insuficientes\"\n",
    "        \n",
    "    try:\n",
    "        chi2, p_valor, _, _ = chi2_contingency(table_no_totals)\n",
    "        \n",
    "        # Formatear el p-valor\n",
    "        p_str = f\"p={p_valor:.4f}\"\n",
    "        if p_valor < 0.05:\n",
    "            p_str += \" (*)\" # Marcador de significancia\n",
    "            \n",
    "        return f\"Chi¬≤={chi2:.2f}; {p_str}\"\n",
    "        \n",
    "    except ValueError as e:\n",
    "        # Pasa si una fila/columna es todo 0\n",
    "        return \"C√°lculo no v√°lido\"\n",
    "# --- Fin de la Funci√≥n de Ayuda ---\n",
    "\n",
    "\n",
    "print(\"Generando reporte unificado con Chi-Cuadrado...\")\n",
    "\n",
    "# --- Preparaci√≥n para el Excel ---\n",
    "output_filename = 'analisis_completo_con_chi2.xlsx'\n",
    "sheet_name = 'Analisis_Completo'\n",
    "\n",
    "# Calcular d√≥nde ir√° la columna de Chi¬≤\n",
    "# 3 niveles de √≠ndice (REGION, ESTADO, Tipo) \n",
    "index_cols_count = 3\n",
    "# Columnas de datos (V5) + 1 (Total)\n",
    "data_cols_count = df_join_pobre['V5'].nunique() + 1\n",
    "# La columna de Chi¬≤ ir√° despu√©s de los √≠ndices y los datos + 1 columna de espacio\n",
    "col_inicio_chi2 = index_cols_count + data_cols_count + 1\n",
    "\n",
    "# Fila actual donde escribir√° Excel\n",
    "fila_actual = 0\n",
    "\n",
    "with pd.ExcelWriter(output_filename, engine='xlsxwriter') as writer:\n",
    "    \n",
    "    # Escribir el t√≠tulo de la columna Chi¬≤\n",
    "    pd.DataFrame(['An√°lisis Chi¬≤ (œá¬≤)']).to_excel(\n",
    "        writer, sheet_name=sheet_name, \n",
    "        startrow=fila_actual, startcol=col_inicio_chi2, \n",
    "        header=False, index=False\n",
    "    )\n",
    "    fila_actual += 2 # Dejar espacio\n",
    "\n",
    "    \n",
    "    # --- 1. TABLA NACIONAL (TOTAL) ---\n",
    "    \n",
    "    # 1a. Calcular Absolutos Nacional\n",
    "    tabla_nac_abs = pd.pivot_table(\n",
    "        df_join_pobre, values='PONDERA2', index='ESTADO', columns='V5',\n",
    "        aggfunc='sum', margins=True, margins_name='Total', fill_value=0\n",
    "    )\n",
    "    # 1b. Calcular Porcentajes Nacional\n",
    "    tabla_nac_pct = tabla_nac_abs.apply(lambda x: (x / x['Total']) * 100).round(2)\n",
    "    \n",
    "    # 1c. Calcular Chi-Cuadrado Nacional\n",
    "    chi2_nac_str = get_chi2_results(tabla_nac_abs)\n",
    "    \n",
    "    # 1d. Apilar Abs/Pct y a√±adir √≠ndice 'Tipo'\n",
    "    tabla_nac_abs['Tipo'] = 'Absoluto'\n",
    "    tabla_nac_pct['Tipo'] = 'Porcentaje'\n",
    "    tabla_nacional_final = pd.concat([tabla_nac_abs, tabla_nac_pct]).set_index('Tipo', append=True)\n",
    "    \n",
    "    # 1e. A√±adir √≠ndice 'REGION' y ordenar\n",
    "    tabla_nacional_listo = pd.concat([tabla_nacional_final], keys=['Total (Nacional)'], names=['REGION'])\n",
    "    tabla_nacional_listo = tabla_nacional_listo.sort_index()\n",
    "    \n",
    "    # 1f. Escribir la tabla principal a Excel\n",
    "    tabla_nacional_listo.to_excel(\n",
    "        writer, sheet_name=sheet_name, \n",
    "        startrow=fila_actual\n",
    "    )\n",
    "    \n",
    "    # 1g. Escribir el resultado de Chi¬≤ alineado verticalmente\n",
    "    fila_chi2 = fila_actual + (tabla_nacional_listo.shape[0] // 2) # Centrado\n",
    "    pd.DataFrame([chi2_nac_str]).to_excel(\n",
    "        writer, sheet_name=sheet_name, \n",
    "        startrow=fila_chi2, startcol=col_inicio_chi2, \n",
    "        header=False, index=False\n",
    "    )\n",
    "    \n",
    "    # 1h. Actualizar la posici√≥n de la fila para la siguiente tabla\n",
    "    fila_actual += tabla_nacional_listo.shape[0] + 2 # +2 para espacio\n",
    "\n",
    "    \n",
    "    # --- 2. TABLAS PARCIALES (POR REGION) ---\n",
    "    \n",
    "    regiones_ordenadas = sorted(df_join_pobre['REGION'].unique())\n",
    "    \n",
    "    for region_id in regiones_ordenadas:\n",
    "        df_region = df_join_pobre[df_join_pobre['REGION'] == region_id]\n",
    "        if df_region.empty:\n",
    "            continue\n",
    "        \n",
    "        # 2a. Calcular Absolutos\n",
    "        tabla_reg_abs = pd.pivot_table(\n",
    "            df_region, values='PONDERA2', index='ESTADO', columns='V5',\n",
    "            aggfunc='sum', margins=True, margins_name='Total', fill_value=0\n",
    "        )\n",
    "        # 2b. Calcular Porcentajes\n",
    "        tabla_reg_pct = tabla_reg_abs.apply(lambda x: (x / x['Total']) * 100).round(2)\n",
    "        \n",
    "        # 2c. Calcular Chi-Cuadrado\n",
    "        chi2_reg_str = get_chi2_results(tabla_reg_abs)\n",
    "        \n",
    "        # 2d. Apilar Abs/Pct y a√±adir √≠ndice 'Tipo'\n",
    "        tabla_reg_abs['Tipo'] = 'Absoluto'\n",
    "        tabla_reg_pct['Tipo'] = 'Porcentaje'\n",
    "        tabla_region_final = pd.concat([tabla_reg_abs, tabla_reg_pct]).set_index('Tipo', append=True)\n",
    "        \n",
    "        # 2e. A√±adir √≠ndice 'REGION' y ordenar\n",
    "        tabla_region_listo = pd.concat([tabla_region_final], keys=[region_id], names=['REGION'])\n",
    "        tabla_region_listo = tabla_region_listo.sort_index()\n",
    "        \n",
    "        # 2f. Escribir la tabla a Excel (sin encabezado esta vez)\n",
    "        tabla_region_listo.to_excel(\n",
    "            writer, sheet_name=sheet_name, \n",
    "            startrow=fila_actual, \n",
    "            header=False # El encabezado ya se escribi√≥ con la tabla nacional\n",
    "        )\n",
    "        \n",
    "        # 2g. Escribir el resultado de Chi¬≤ alineado\n",
    "        fila_chi2 = fila_actual + (tabla_region_listo.shape[0] // 2) # Centrado\n",
    "        pd.DataFrame([chi2_reg_str]).to_excel(\n",
    "            writer, sheet_name=sheet_name, \n",
    "            startrow=fila_chi2, startcol=col_inicio_chi2, \n",
    "            header=False, index=False\n",
    "        )\n",
    "        \n",
    "        # 2h. Actualizar la fila\n",
    "        fila_actual += tabla_region_listo.shape[0] + 2 # +2 para espacio\n",
    "\n",
    "print(f\"¬°Listo! An√°lisis completo guardado en '{output_filename}'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f9e273fe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculando Regresi√≥n Log√≠stica Nacional...\n",
      "Calculando Regresiones Log√≠sticas por Regi√≥n...\n",
      "  > Regi√≥n Cuyo calculada.\n",
      "  > Regi√≥n Gran Buenos Aires calculada.\n",
      "  > Regi√≥n Noreste calculada.\n",
      "  > Regi√≥n Noroeste calculada.\n",
      "  > Regi√≥n Pampeana calculada.\n",
      "  > Regi√≥n Patagonia calculada.\n",
      "\n",
      "==================================================\n",
      "RESULTADOS DE LA REGRESI√ìN LOG√çSTICA\n",
      "==================================================\n",
      "                   Beta (Intercept)  Beta (V5[T.Percibe])  P-Valor (Intercept)  P-Valor (V5[T.Percibe])  Nagelkerke R¬≤  N (Suma Ponderador)\n",
      "Modelo                                                                                                                                     \n",
      "Total (Nacional)          -0.207465              0.074837         7.590749e-25                 0.044830       0.000287                14030\n",
      "Cuyo                      -0.122802             -0.010573         9.480476e-02                 0.941435       0.000006                 1577\n",
      "Gran Buenos Aires         -0.222493              0.174601         2.757961e-14                 0.001145       0.006019                 1751\n",
      "Noreste                   -0.194527             -0.264815         1.872855e-02                 0.071906       0.003844                 1635\n",
      "Noroeste                  -0.147655              0.016602         9.854487e-03                 0.870320       0.000007                 3670\n",
      "Pampeana                  -0.232124              0.050332         2.583843e-08                 0.525128       0.000098                 4106\n",
      "Patagonia                 -0.257149             -0.221302         2.225244e-02                 0.347180       0.001926                 1291\n",
      "\n",
      "--- Fin del An√°lisis de Regresi√≥n ---\n"
     ]
    }
   ],
   "source": [
    "# statsmodels necesita que la variable dependiente (Y) sea num√©rica (0 o 1).\n",
    "# Vamos a crear 'ESTADO_BIN'. Asumiremos 'Activo' = 1 y 'Inactivo' = 0.\n",
    "df_regresion = df_join_pobre.copy()\n",
    "df_regresion['ESTADO_BIN'] = df_regresion['ESTADO'].apply(lambda x: 1 if x == 'Activo' else 0)\n",
    "\n",
    "# La f√≥rmula. statsmodels manejar√° 'V5' (Percibe/No Percibe) como una variable dummy.\n",
    "# Autom√°ticamente usar√° una categor√≠a (alfab√©ticamente, 'No Percibe') como base.\n",
    "formula = 'ESTADO_BIN ~ V5'\n",
    "\n",
    "# --- PASO 2: Funci√≥n de Ayuda para R¬≤ de Nagelkerke ---\n",
    "# statsmodels por defecto da el R¬≤ de McFadden, as√≠ que calculamos el de Nagelkerke.\n",
    "def get_nagelkerke_r2(results):\n",
    "    \"\"\"Calcula el Pseudo R¬≤ de Nagelkerke a partir de un resultado de statsmodels.\"\"\"\n",
    "    try:\n",
    "        llf = results.llf  # Log-likelihood del modelo completo\n",
    "        lln = results.llnull # Log-likelihood del modelo nulo (solo intercepto)\n",
    "        n = results.nobs   # N√∫mero de observaciones (suma de ponderadores)\n",
    "        \n",
    "        # Calcular R¬≤ de Cox & Snell\n",
    "        r2_cs = 1 - (np.exp(lln - llf))**(2/n)\n",
    "        \n",
    "        # Calcular el R¬≤ m√°ximo\n",
    "        r2_max_nagel = 1 - (np.exp(lln))**(2/n)\n",
    "        \n",
    "        if r2_max_nagel == 0:\n",
    "            return 0.0\n",
    "            \n",
    "        return r2_cs / r2_max_nagel\n",
    "    except Exception:\n",
    "        return np.nan\n",
    "\n",
    "# --- PASO 3: Correr modelos y guardar resultados ---\n",
    "results_list = []\n",
    "\n",
    "# Corremos primero el modelo Nacional\n",
    "print(\"Calculando Regresi√≥n Log√≠stica Nacional...\")\n",
    "try:\n",
    "    df_nat = df_regresion\n",
    "    pesos_nat = df_nat['PONDERA2']\n",
    "    \n",
    "    # Usamos GLM (Modelo Lineal Generalizado) con familia Binomial (log√≠stica)\n",
    "    # y 'freq_weights' para aplicar el ponderador PONDERA2.\n",
    "    modelo_nat = smf.glm(formula=formula, \n",
    "                         data=df_nat, \n",
    "                         family=sm.families.Binomial(), \n",
    "                         freq_weights=pesos_nat)\n",
    "    results_nat = modelo_nat.fit()\n",
    "    \n",
    "    # Extraer resultados\n",
    "    coefs_nat = results_nat.params\n",
    "    pvals_nat = results_nat.pvalues\n",
    "    nagel_nat = get_nagelkerke_r2(results_nat)\n",
    "    \n",
    "    # Detectar el nombre de la columna V5 (ej. \"V5[T.Percibe]\")\n",
    "    v5_col_name = [col for col in coefs_nat.index if 'V5[' in col][0]\n",
    "    \n",
    "    results_list.append({\n",
    "        'Modelo': 'Total (Nacional)',\n",
    "        'Beta (Intercept)': coefs_nat['Intercept'],\n",
    "        f'Beta ({v5_col_name})': coefs_nat[v5_col_name],\n",
    "        'P-Valor (Intercept)': pvals_nat['Intercept'],\n",
    "        f'P-Valor ({v5_col_name})': pvals_nat[v5_col_name],\n",
    "        'Nagelkerke R¬≤': nagel_nat,\n",
    "        'N (Suma Ponderador)': results_nat.nobs\n",
    "    })\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"Error al calcular modelo nacional: {e}\")\n",
    "\n",
    "# Ahora iteramos y corremos el modelo para CADA REGI√ìN\n",
    "print(\"Calculando Regresiones Log√≠sticas por Regi√≥n...\")\n",
    "regiones_ordenadas = sorted(df_regresion['REGION'].unique())\n",
    "\n",
    "for region_id in regiones_ordenadas:\n",
    "    df_region = df_regresion[df_regresion['REGION'] == region_id]\n",
    "    \n",
    "    # Asegurarnos de que hay suficientes datos y variabilidad para correr el modelo\n",
    "    if df_region.empty or df_region['V5'].nunique() < 2 or df_region['ESTADO_BIN'].nunique() < 2:\n",
    "        print(f\"  > Omitiendo Regi√≥n {region_id}: datos insuficientes o sin variabilidad.\")\n",
    "        continue\n",
    "        \n",
    "    try:\n",
    "        pesos_reg = df_region['PONDERA2']\n",
    "        modelo_reg = smf.glm(formula=formula, \n",
    "                             data=df_region, \n",
    "                             family=sm.families.Binomial(), \n",
    "                             freq_weights=pesos_reg)\n",
    "        results_reg = modelo_reg.fit()\n",
    "        \n",
    "        # Extraer resultados\n",
    "        coefs_reg = results_reg.params\n",
    "        pvals_reg = results_reg.pvalues\n",
    "        nagel_reg = get_nagelkerke_r2(results_reg)\n",
    "        \n",
    "        v5_col_name_reg = [col for col in coefs_reg.index if 'V5[' in col][0]\n",
    "        \n",
    "        results_list.append({\n",
    "            'Modelo': region_id,\n",
    "            'Beta (Intercept)': coefs_reg['Intercept'],\n",
    "            f'Beta ({v5_col_name})': coefs_reg[v5_col_name_reg],\n",
    "            'P-Valor (Intercept)': pvals_reg['Intercept'],\n",
    "            f'P-Valor ({v5_col_name})': pvals_reg[v5_col_name_reg],\n",
    "            'Nagelkerke R¬≤': nagel_reg,\n",
    "            'N (Suma Ponderador)': results_reg.nobs\n",
    "        })\n",
    "        print(f\"  > Regi√≥n {region_id} calculada.\")\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"  > Error al calcular modelo para {region_id}: {e}\")\n",
    "\n",
    "# --- PASO 4: Presentar los resultados en una tabla ---\n",
    "if results_list:\n",
    "    df_summary = pd.DataFrame(results_list)\n",
    "    df_summary = df_summary.set_index('Modelo')\n",
    "    \n",
    "    print(\"\\n\" + \"=\"*50)\n",
    "    print(\"RESULTADOS DE LA REGRESI√ìN LOG√çSTICA\")\n",
    "    print(\"=\"*50)\n",
    "    # Usamos .to_string() para asegurarnos de que se impriman todas las columnas\n",
    "    print(df_summary.to_string())\n",
    "else:\n",
    "    print(\"No se pudieron generar resultados de regresi√≥n.\")\n",
    "\n",
    "print(\"\\n--- Fin del An√°lisis de Regresi√≥n ---\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv (3.13.1)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

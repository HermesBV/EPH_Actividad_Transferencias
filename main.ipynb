{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1b74e314",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from pandas.plotting import table\n",
    "import numpy as np  \n",
    "import matplotlib.pyplot as plt\n",
    "import openpyxl\n",
    "from IPython.display import HTML\n",
    "import pingouin as pg\n",
    "import os\n",
    "from scipy.stats import chi2_contingency\n",
    "import statsmodels.api as sm\n",
    "import statsmodels.formula.api as smf\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3e67e32a",
   "metadata": {},
   "outputs": [],
   "source": [
    "xl_usu = 'usu_individual_T125.xlsx'  \n",
    "dfusu = pd.read_excel(xl_usu)\n",
    "dfusu = dfusu.loc[:, ['CODUSU','NRO_HOGAR','COMPONENTE', 'ESTADO','V5_01_M','V5_02_M','V5_03_M','PONDERA']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "96a45606",
   "metadata": {},
   "outputs": [],
   "source": [
    "xl_hog = 'usu_hogar_T125.xlsx'  \n",
    "dfhog = pd.read_excel(xl_hog)\n",
    "dfhog = dfhog.loc[:, ['CODUSU','NRO_HOGAR','DECIFR','REGION','V5_01','V5_02','V5_03']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5ad8a59b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CODUSU</th>\n",
       "      <th>NRO_HOGAR</th>\n",
       "      <th>DECIFR</th>\n",
       "      <th>REGION</th>\n",
       "      <th>V5_01</th>\n",
       "      <th>V5_02</th>\n",
       "      <th>V5_03</th>\n",
       "      <th>V5</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>TQRMNOQVSHKOLNCDEGGFB00858441</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>42</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>TQSMNORTSHMOLTCDEGGFB00877605</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>42</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>TQRMNOQQXHMMMLCDEGGFB00877606</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>42</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>TQRMNOTTWHMMLOCDEFIAH00877819</td>\n",
       "      <td>1</td>\n",
       "      <td>12</td>\n",
       "      <td>43</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>TQRMNORQQHLMKOCDEHIBB00853810</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>40</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                          CODUSU  NRO_HOGAR  DECIFR  REGION  V5_01  V5_02  \\\n",
       "0  TQRMNOQVSHKOLNCDEGGFB00858441          1       1      42      2      2   \n",
       "1  TQSMNORTSHMOLTCDEGGFB00877605          1       6      42      2      2   \n",
       "2  TQRMNOQQXHMMMLCDEGGFB00877606          1       4      42      2      2   \n",
       "3  TQRMNOTTWHMMLOCDEFIAH00877819          1      12      43      2      2   \n",
       "4  TQRMNORQQHLMKOCDEHIBB00853810          2       1      40      2      2   \n",
       "\n",
       "   V5_03  V5  \n",
       "0      2   2  \n",
       "1      2   2  \n",
       "2      2   2  \n",
       "3      2   2  \n",
       "4      2   2  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# V5 = 1 si ALGUNA variable es 1, 2 solo si TODAS son 2\n",
    "dfhog['V5'] = 2  # Inicializar con 2 (asumiendo que todas son 2)\n",
    "\n",
    "# Si ALGUNA variable es 1, entonces V5 = 1\n",
    "mask_alguna_1 = (dfhog['V5_01'] == 1) | (dfhog['V5_02'] == 1) | (dfhog['V5_03'] == 1)\n",
    "dfhog.loc[mask_alguna_1, 'V5'] = 1\n",
    "\n",
    "#print(dfhog['V5'].value_counts().sort_index())\n",
    "dfhog.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "cb73e748",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DECIFR\n",
      "1    1457\n",
      "4    1350\n",
      "2    1333\n",
      "5    1287\n",
      "3    1273\n",
      "Name: count, dtype: int64\n",
      "ESTADO\n",
      "1    20076\n",
      "3    18866\n",
      "2     1381\n",
      "Name: count, dtype: int64\n",
      "---------------------------------------------------\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 6700 entries, 0 to 15979\n",
      "Data columns (total 8 columns):\n",
      " #   Column     Non-Null Count  Dtype \n",
      "---  ------     --------------  ----- \n",
      " 0   CODUSU     6700 non-null   object\n",
      " 1   NRO_HOGAR  6700 non-null   int64 \n",
      " 2   DECIFR     6700 non-null   int64 \n",
      " 3   REGION     6700 non-null   int64 \n",
      " 4   V5_01      6700 non-null   int64 \n",
      " 5   V5_02      6700 non-null   int64 \n",
      " 6   V5_03      6700 non-null   int64 \n",
      " 7   V5         6700 non-null   int64 \n",
      "dtypes: int64(7), object(1)\n",
      "memory usage: 471.1+ KB\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 40323 entries, 0 to 45424\n",
      "Data columns (total 8 columns):\n",
      " #   Column      Non-Null Count  Dtype \n",
      "---  ------      --------------  ----- \n",
      " 0   CODUSU      40323 non-null  object\n",
      " 1   NRO_HOGAR   40323 non-null  int64 \n",
      " 2   COMPONENTE  40323 non-null  int64 \n",
      " 3   ESTADO      40323 non-null  int64 \n",
      " 4   V5_01_M     40323 non-null  int64 \n",
      " 5   V5_02_M     40323 non-null  int64 \n",
      " 6   V5_03_M     40323 non-null  int64 \n",
      " 7   PONDERA     40323 non-null  int64 \n",
      "dtypes: int64(7), object(1)\n",
      "memory usage: 2.8+ MB\n"
     ]
    }
   ],
   "source": [
    "#hogares: filtrar 50% más pobre (0 y 12)\n",
    "\n",
    "dfhog_pobre = dfhog[dfhog['DECIFR'].isin([1, 2, 3, 4, 5])]\n",
    "print(dfhog_pobre['DECIFR'].value_counts())\n",
    "\n",
    "#persona: filtrar por Estado 1 (ocupado), 2 (desocupado) y 3 (inactivo)\n",
    "dfusu = dfusu[dfusu['ESTADO'].isin([1, 2, 3])]\n",
    "print(dfusu['ESTADO'].value_counts())\n",
    "\n",
    "print(\"---------------------------------------------------\")\n",
    "dfhog_pobre.info()\n",
    "dfusu.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f4c0d12c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 14030 entries, 0 to 14029\n",
      "Data columns (total 14 columns):\n",
      " #   Column      Non-Null Count  Dtype \n",
      "---  ------      --------------  ----- \n",
      " 0   CODUSU      14030 non-null  object\n",
      " 1   NRO_HOGAR   14030 non-null  int64 \n",
      " 2   DECIFR      14030 non-null  int64 \n",
      " 3   REGION      14030 non-null  int64 \n",
      " 4   V5_01       14030 non-null  int64 \n",
      " 5   V5_02       14030 non-null  int64 \n",
      " 6   V5_03       14030 non-null  int64 \n",
      " 7   V5          14030 non-null  int64 \n",
      " 8   COMPONENTE  14030 non-null  int64 \n",
      " 9   ESTADO      14030 non-null  int64 \n",
      " 10  V5_01_M     14030 non-null  int64 \n",
      " 11  V5_02_M     14030 non-null  int64 \n",
      " 12  V5_03_M     14030 non-null  int64 \n",
      " 13  PONDERA     14030 non-null  int64 \n",
      "dtypes: int64(13), object(1)\n",
      "memory usage: 1.5+ MB\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CODUSU</th>\n",
       "      <th>NRO_HOGAR</th>\n",
       "      <th>DECIFR</th>\n",
       "      <th>REGION</th>\n",
       "      <th>V5_01</th>\n",
       "      <th>V5_02</th>\n",
       "      <th>V5_03</th>\n",
       "      <th>V5</th>\n",
       "      <th>COMPONENTE</th>\n",
       "      <th>ESTADO</th>\n",
       "      <th>V5_01_M</th>\n",
       "      <th>V5_02_M</th>\n",
       "      <th>V5_03_M</th>\n",
       "      <th>PONDERA</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>TQRMNOQVSHKOLNCDEGGFB00858441</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>42</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>526</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>TQRMNOQVSHKOLNCDEGGFB00858441</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>42</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>526</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>TQRMNOQQXHMMMLCDEGGFB00877606</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>42</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>446</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>TQRMNOQQXHMMMLCDEGGFB00877606</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>42</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>446</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>TQRMNORQQHLMKOCDEHIBB00853810</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>40</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>132</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>TQRMNOTPYHMOLQCDEFMDB00877823</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>43</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>199</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>TQRMNOTPYHMOLQCDEFMDB00877823</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>43</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>199</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>TQRMNORVVHLLLPCDEFMDB00852190</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>43</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>146</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>TQRMNOQTTHKMKSCDEFMDB00857883</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>43</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>234</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>TQRMNOPXWHMOKSCDEOJAH00877825</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>44</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>113</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>TQRMNORPXHLLKRCDEOJAH00856304</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>44</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>92</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>TQRMNORPXHLLKRCDEOJAH00856304</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>44</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>92</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>TQRMNORPXHLLKRCDEOJAH00856304</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>44</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>92</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>TQRMNOPWTHLOKTCDEOJAH00856786</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>44</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>46</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>TQSMNOPSYHKMMLCDEFKID00861533</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>43</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>720</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>TQSMNOPSYHKMMLCDEFKID00861533</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>43</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>60000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>720</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>TQRMNOSVSHKMMLCDEFKID00861389</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>43</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>586</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>TQRMNOSVSHKMMLCDEFKID00861389</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>43</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>586</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>TQRMNOSUXHLLLUCDEFKID00861457</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>43</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1770</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>TQRMNOPSXHLMLMCDEIJAH00855495</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3440</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                           CODUSU  NRO_HOGAR  DECIFR  REGION  V5_01  V5_02  \\\n",
       "0   TQRMNOQVSHKOLNCDEGGFB00858441          1       1      42      2      2   \n",
       "1   TQRMNOQVSHKOLNCDEGGFB00858441          1       1      42      2      2   \n",
       "2   TQRMNOQQXHMMMLCDEGGFB00877606          1       4      42      2      2   \n",
       "3   TQRMNOQQXHMMMLCDEGGFB00877606          1       4      42      2      2   \n",
       "4   TQRMNORQQHLMKOCDEHIBB00853810          2       1      40      2      2   \n",
       "5   TQRMNOTPYHMOLQCDEFMDB00877823          1       5      43      2      2   \n",
       "6   TQRMNOTPYHMOLQCDEFMDB00877823          1       5      43      2      2   \n",
       "7   TQRMNORVVHLLLPCDEFMDB00852190          1       3      43      2      2   \n",
       "8   TQRMNOQTTHKMKSCDEFMDB00857883          1       3      43      2      2   \n",
       "9   TQRMNOPXWHMOKSCDEOJAH00877825          1       3      44      2      2   \n",
       "10  TQRMNORPXHLLKRCDEOJAH00856304          1       5      44      2      2   \n",
       "11  TQRMNORPXHLLKRCDEOJAH00856304          1       5      44      2      2   \n",
       "12  TQRMNORPXHLLKRCDEOJAH00856304          1       5      44      2      2   \n",
       "13  TQRMNOPWTHLOKTCDEOJAH00856786          1       2      44      2      2   \n",
       "14  TQSMNOPSYHKMMLCDEFKID00861533          1       4      43      1      2   \n",
       "15  TQSMNOPSYHKMMLCDEFKID00861533          1       4      43      1      2   \n",
       "16  TQRMNOSVSHKMMLCDEFKID00861389          1       3      43      2      2   \n",
       "17  TQRMNOSVSHKMMLCDEFKID00861389          1       3      43      2      2   \n",
       "18  TQRMNOSUXHLLLUCDEFKID00861457          1       1      43      2      2   \n",
       "19  TQRMNOPSXHLMLMCDEIJAH00855495          1       3       1      2      2   \n",
       "\n",
       "    V5_03  V5  COMPONENTE  ESTADO  V5_01_M  V5_02_M  V5_03_M  PONDERA  \n",
       "0       2   2           1       1        0        0        0      526  \n",
       "1       2   2           2       3        0        0        0      526  \n",
       "2       2   2           1       3        0        0        0      446  \n",
       "3       2   2           2       3        0        0        0      446  \n",
       "4       2   2           1       3        0        0        0      132  \n",
       "5       2   2           1       1        0        0        0      199  \n",
       "6       2   2           2       1        0        0        0      199  \n",
       "7       2   2           1       3        0        0        0      146  \n",
       "8       2   2           1       1        0        0        0      234  \n",
       "9       2   2           1       1        0        0        0      113  \n",
       "10      2   2           1       2        0        0        0       92  \n",
       "11      2   2           2       3        0        0        0       92  \n",
       "12      2   2           3       3        0        0        0       92  \n",
       "13      2   2           1       3        0        0        0       46  \n",
       "14      2   1           1       1        0        0        0      720  \n",
       "15      2   1           2       1    60000        0        0      720  \n",
       "16      2   2           1       3        0        0        0      586  \n",
       "17      2   2           2       3        0        0        0      586  \n",
       "18      2   2           1       3        0        0        0     1770  \n",
       "19      2   2           1       3        0        0        0     3440  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Juntar tablas (left hogares pobres, right individuos)\n",
    "df_join_pobre = dfhog_pobre.merge(dfusu, how='left', on=['CODUSU', 'NRO_HOGAR'])\n",
    "df_join_pobre.info()\n",
    "df_join_pobre.head(20)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "45ada7d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 14030 entries, 0 to 14029\n",
      "Data columns (total 15 columns):\n",
      " #   Column      Non-Null Count  Dtype \n",
      "---  ------      --------------  ----- \n",
      " 0   CODUSU      14030 non-null  object\n",
      " 1   NRO_HOGAR   14030 non-null  int64 \n",
      " 2   DECIFR      14030 non-null  int64 \n",
      " 3   REGION      14030 non-null  int64 \n",
      " 4   V5_01       14030 non-null  int64 \n",
      " 5   V5_02       14030 non-null  int64 \n",
      " 6   V5_03       14030 non-null  int64 \n",
      " 7   V5          14030 non-null  int64 \n",
      " 8   COMPONENTE  14030 non-null  int64 \n",
      " 9   ESTADO      14030 non-null  int64 \n",
      " 10  V5_01_M     14030 non-null  int64 \n",
      " 11  V5_02_M     14030 non-null  int64 \n",
      " 12  V5_03_M     14030 non-null  int64 \n",
      " 13  PONDERA     14030 non-null  int64 \n",
      " 14  UID         14030 non-null  object\n",
      "dtypes: int64(13), object(2)\n",
      "memory usage: 1.6+ MB\n"
     ]
    }
   ],
   "source": [
    "# Crear UID único para el DataFrame completo\n",
    "df_join_pobre['UID'] = (\n",
    "    df_join_pobre['CODUSU'].astype(str) + '_' + \n",
    "    df_join_pobre['NRO_HOGAR'].astype(str) + '_' + \n",
    "    df_join_pobre['COMPONENTE'].astype(str)\n",
    ")   \n",
    "df_join_pobre.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f3e846b8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Variables recodificadas con sufijo _CAT.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ESTADO_CAT</th>\n",
       "      <th>V5_CAT</th>\n",
       "      <th>REGION_CAT</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Activo</td>\n",
       "      <td>No Percibe</td>\n",
       "      <td>Cuyo</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Inactivo</td>\n",
       "      <td>No Percibe</td>\n",
       "      <td>Cuyo</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Inactivo</td>\n",
       "      <td>No Percibe</td>\n",
       "      <td>Cuyo</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Inactivo</td>\n",
       "      <td>No Percibe</td>\n",
       "      <td>Cuyo</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Inactivo</td>\n",
       "      <td>No Percibe</td>\n",
       "      <td>Noroeste</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  ESTADO_CAT      V5_CAT REGION_CAT\n",
       "0     Activo  No Percibe       Cuyo\n",
       "1   Inactivo  No Percibe       Cuyo\n",
       "2   Inactivo  No Percibe       Cuyo\n",
       "3   Inactivo  No Percibe       Cuyo\n",
       "4   Inactivo  No Percibe   Noroeste"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Recodificar variables (fusionar 1 y 2 como Activo; v5 con percibe/no-percibe)\n",
    "# Creamos nuevas columnas con sufijo _CAT para mantener las originales\n",
    "df_join_pobre['ESTADO_CAT'] = df_join_pobre['ESTADO'].replace({1: 'Activo', 2: 'Activo', 3: 'Inactivo'})\n",
    "df_join_pobre['V5_CAT'] = df_join_pobre['V5'].replace({1: 'Percibe', 2: 'No Percibe'})\n",
    "df_join_pobre['REGION_CAT'] = df_join_pobre['REGION'].replace({1: 'Gran Buenos Aires', 40: 'Noroeste', 41: 'Noreste', 42: 'Cuyo', 43: 'Pampeana', 44: 'Patagonia'})\n",
    "\n",
    "print(\"Variables recodificadas con sufijo _CAT.\")\n",
    "df_join_pobre[['ESTADO_CAT', 'V5_CAT', 'REGION_CAT']].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8268254f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14030\n",
      "8225518\n",
      "14030.0\n"
     ]
    }
   ],
   "source": [
    "#ponderador casero\n",
    "n = len(df_join_pobre)\n",
    "N_t = df_join_pobre['PONDERA'].sum()\n",
    "ajuste = n / N_t\n",
    "df_join_pobre['PONDERA2'] = df_join_pobre['PONDERA'] * ajuste\n",
    "#verif ponderadores\n",
    "print(n)\n",
    "print(df_join_pobre['PONDERA'].sum())\n",
    "print(df_join_pobre['PONDERA2'].sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ef184dd5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writer de Excel preparado para guardar en: Output_EPH_Transferencias_Actividad.xlsx\n"
     ]
    }
   ],
   "source": [
    "# --- Preparación para el Excel ---\n",
    "# Definimos el nombre del archivo y creamos el \"escritor\" de Excel.\n",
    "# Dejamos el writer \"abierto\" para agregarle pestañas en las celdas siguientes.\n",
    "output_filename = 'Output_EPH_Transferencias_Actividad.xlsx'\n",
    "writer = pd.ExcelWriter(output_filename, engine='xlsxwriter')\n",
    "\n",
    "# --- Función de Ayuda para Chi-Cuadrado ---\n",
    "def get_chi2_results(abs_table):\n",
    "    \"\"\"Calcula Chi² y devuelve un string formateado.\"\"\"\n",
    "    table_no_totals = abs_table.iloc[:-1, :-1]\n",
    "    if table_no_totals.empty or table_no_totals.sum().sum() == 0:\n",
    "        return \"Datos insuficientes\"\n",
    "    try:\n",
    "        chi2, p_valor, _, _ = chi2_contingency(table_no_totals)\n",
    "        p_str = f\"p={p_valor:.4f}\"\n",
    "        if p_valor < 0.05:\n",
    "            p_str += \" (*)\"\n",
    "        return f\"Chi²={chi2:.2f}; {p_str}\"\n",
    "    except ValueError as e:\n",
    "        return f\"Cálculo no válido ({e})\"\n",
    "\n",
    "print(f\"Writer de Excel preparado para guardar en: {output_filename}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "ebde617b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generando Pestaña 1: 'Analisis_Tabular'...\n",
      "Pestaña 'Analisis_Tabular' generada.\n"
     ]
    }
   ],
   "source": [
    "# --- PESTAÑA 1: ANÁLISIS TABULAR (CHI-CUADRADO) ---\n",
    "print(\"Generando Pestaña 1: 'Analisis_Tabular'...\")\n",
    "sheet_name_chi2 = 'Analisis_Tabular'\n",
    "\n",
    "# Calcular dónde irá la columna de Chi²\n",
    "index_cols_count = 3 # REGION_CAT, ESTADO_CAT, Tipo\n",
    "data_cols_count = df_join_pobre['V5_CAT'].nunique() + 1 # Percibe, No Percibe, Total\n",
    "col_inicio_chi2 = index_cols_count + data_cols_count + 1\n",
    "fila_actual = 0\n",
    "\n",
    "# Escribir el título de la columna Chi²\n",
    "pd.DataFrame(['Análisis Chi² (χ²)']).to_excel(\n",
    "    writer, sheet_name=sheet_name_chi2, \n",
    "    startrow=fila_actual, startcol=col_inicio_chi2, \n",
    "    header=False, index=False\n",
    ")\n",
    "fila_actual += 2\n",
    "\n",
    "# --- 1. TABLA NACIONAL (TOTAL) ---\n",
    "tabla_nac_abs = pd.pivot_table(\n",
    "    df_join_pobre, values='PONDERA2', index='ESTADO_CAT', columns='V5_CAT',\n",
    "    aggfunc='sum', margins=True, margins_name='Total', fill_value=0\n",
    ")\n",
    "tabla_nac_pct = tabla_nac_abs.apply(lambda x: (x / x['Total']) * 100).round(2)\n",
    "chi2_nac_str = get_chi2_results(tabla_nac_abs)\n",
    "\n",
    "tabla_nac_abs['Tipo'] = 'Absoluto'\n",
    "tabla_nac_pct['Tipo'] = 'Porcentaje'\n",
    "tabla_nacional_final = pd.concat([tabla_nac_abs, tabla_nac_pct]).set_index('Tipo', append=True)\n",
    "tabla_nacional_listo = pd.concat([tabla_nacional_final], keys=['Total (Nacional)'], names=['REGION_CAT'])\n",
    "tabla_nacional_listo = tabla_nacional_listo.sort_index()\n",
    "\n",
    "tabla_nacional_listo.to_excel(writer, sheet_name=sheet_name_chi2, startrow=fila_actual)\n",
    "\n",
    "fila_chi2 = fila_actual + (tabla_nacional_listo.shape[0] // 2)\n",
    "pd.DataFrame([chi2_nac_str]).to_excel(\n",
    "    writer, sheet_name=sheet_name_chi2, \n",
    "    startrow=fila_chi2, startcol=col_inicio_chi2, \n",
    "    header=False, index=False\n",
    ")\n",
    "fila_actual += tabla_nacional_listo.shape[0] + 2\n",
    "\n",
    "# --- 2. TABLAS PARCIALES (POR REGION) ---\n",
    "regiones_ordenadas = sorted(df_join_pobre['REGION_CAT'].unique())\n",
    "\n",
    "for region_id in regiones_ordenadas:\n",
    "    df_region = df_join_pobre[df_join_pobre['REGION_CAT'] == region_id]\n",
    "    if df_region.empty:\n",
    "        continue\n",
    "    \n",
    "    tabla_reg_abs = pd.pivot_table(\n",
    "        df_region, values='PONDERA2', index='ESTADO_CAT', columns='V5_CAT',\n",
    "        aggfunc='sum', margins=True, margins_name='Total', fill_value=0\n",
    "    )\n",
    "    tabla_reg_pct = tabla_reg_abs.apply(lambda x: (x / x['Total']) * 100).round(2)\n",
    "    chi2_reg_str = get_chi2_results(tabla_reg_abs)\n",
    "    \n",
    "    tabla_reg_abs['Tipo'] = 'Absoluto'\n",
    "    tabla_reg_pct['Tipo'] = 'Porcentaje'\n",
    "    tabla_region_final = pd.concat([tabla_reg_abs, tabla_reg_pct]).set_index('Tipo', append=True)\n",
    "    \n",
    "    tabla_region_listo = pd.concat([tabla_region_final], keys=[region_id], names=['REGION_CAT'])\n",
    "    tabla_region_listo = tabla_region_listo.sort_index()\n",
    "    \n",
    "    tabla_region_listo.to_excel(\n",
    "        writer, sheet_name=sheet_name_chi2, \n",
    "        startrow=fila_actual, \n",
    "        header=False # El encabezado ya se escribió con la tabla nacional\n",
    "    )\n",
    "    \n",
    "    fila_chi2 = fila_actual + (tabla_region_listo.shape[0] // 2)\n",
    "    pd.DataFrame([chi2_reg_str]).to_excel(\n",
    "        writer, sheet_name=sheet_name_chi2, \n",
    "        startrow=fila_chi2, startcol=col_inicio_chi2, \n",
    "        header=False, index=False\n",
    "    )\n",
    "    fila_actual += tabla_region_listo.shape[0] + 2\n",
    "\n",
    "print(\"Pestaña 'Analisis_Tabular' generada.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "537adcaf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generando Pestaña 2: 'Analisis_Regresion'...\n",
      "  Calculando: Regresión Logística Múltiple (Nacional)...\n",
      "  Calculando: Análisis Estratificado (Simple por Región)...\n",
      "  > Región Cuyo calculada.\n",
      "  > Región Gran Buenos Aires calculada.\n",
      "  > Región Noreste calculada.\n",
      "  > Región Noroeste calculada.\n",
      "  > Región Pampeana calculada.\n",
      "  > Región Patagonia calculada.\n",
      "Pestaña 'Analisis_Regresion' generada.\n"
     ]
    }
   ],
   "source": [
    "# --- PESTAÑA 2: ANÁLISIS DE REGRESIÓN LOGÍSTICA (COEFICIENTES) ---\n",
    "print(\"Generando Pestaña 2: 'Analisis_Regresion'...\")\n",
    "sheet_name_reg = 'Analisis_Regresion'\n",
    "\n",
    "# --- Preparación para la Regresión ---\n",
    "\n",
    "# 1. Crear variable dependiente Binaria (1=Activo, 0=Inactivo)\n",
    "df_join_pobre['ESTADO_BIN'] = df_join_pobre['ESTADO_CAT'].apply(lambda x: 1 if x == 'Activo' else 0)\n",
    "\n",
    "# 2. Función de Ayuda para R² de Nagelkerke\n",
    "def get_nagelkerke_r2(results):\n",
    "    \"\"\"Calcula el Pseudo R² de Nagelkerke a partir de un resultado de statsmodels.\"\"\"\n",
    "    try:\n",
    "        llf = results.llf  # Log-likelihood del modelo completo\n",
    "        lln = results.llnull # Log-likelihood del modelo nulo (solo intercepto)\n",
    "        n = results.nobs   # Número de observaciones (suma de ponderadores)\n",
    "        \n",
    "        r2_cs = 1 - (np.exp(lln - llf))**(2/n)\n",
    "        r2_max_nagel = 1 - (np.exp(lln))**(2/n)\n",
    "        \n",
    "        if r2_max_nagel == 0: return 0.0\n",
    "        return r2_cs / r2_max_nagel\n",
    "    except Exception:\n",
    "        return np.nan\n",
    "\n",
    "# 3. Lista para guardar todos los resultados de regresión\n",
    "all_regression_results = []\n",
    "\n",
    "# --- Modelo 1: REGRESIÓN LOGÍSTICA MÚLTIPLE (NACIONAL) ---\n",
    "print(\"  Calculando: Regresión Logística Múltiple (Nacional)...\")\n",
    "\n",
    "try:\n",
    "    df_nat = df_join_pobre\n",
    "    pesos_nat = df_nat['PONDERA2']\n",
    "    \n",
    "    # Usamos C() para asegurar que statsmodels trate V5_CAT y REGION_CAT como categóricas\n",
    "    formula_multi = 'ESTADO_BIN ~ C(V5_CAT) + C(REGION_CAT)'\n",
    "    \n",
    "    # Guardamos el modelo en 'modelo_nat' para usarlo en la celda siguiente\n",
    "    modelo_nat = smf.glm(formula=formula_multi, \n",
    "                         data=df_nat, \n",
    "                         family=sm.families.Binomial(), \n",
    "                         freq_weights=pesos_nat).fit()\n",
    "    \n",
    "    # Extraer resultados y ponerlos en un DataFrame\n",
    "    results_df = pd.DataFrame({\n",
    "        'Coef. (Beta)': modelo_nat.params,\n",
    "        'Odds Ratio (e^Beta)': np.exp(modelo_nat.params), # Beta Exponenciado\n",
    "        'Error Estándar': modelo_nat.bse,\n",
    "        'P-Valor': modelo_nat.pvalues\n",
    "    })\n",
    "    \n",
    "    # Calcular Nagelkerke R² para el modelo general\n",
    "    nagel_nat = get_nagelkerke_r2(modelo_nat)\n",
    "    results_df.loc['Nagelkerke R²', 'Coef. (Beta)'] = nagel_nat\n",
    "    results_df.loc['N (Ponderado)', 'Coef. (Beta)'] = modelo_nat.nobs\n",
    "    \n",
    "    # Añadir identificadores al índice\n",
    "    results_df['Modelo'] = 'Logístico Múltiple (Nacional)'\n",
    "    results_df['Estrato'] = 'Total (Nacional)'\n",
    "    results_df = results_df.reset_index().rename(columns={'index': 'Variable'})\n",
    "    \n",
    "    all_regression_results.append(results_df)\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"  ERROR al calcular modelo nacional: {e}\")\n",
    "\n",
    "# --- Modelo 2: ANÁLISIS ESTRATIFICADO (REGRESIONES SIMPLES POR REGIÓN) ---\n",
    "print(\"  Calculando: Análisis Estratificado (Simple por Región)...\")\n",
    "\n",
    "formula_simple = 'ESTADO_BIN ~ C(V5_CAT)'\n",
    "regiones_ordenadas = sorted(df_join_pobre['REGION_CAT'].unique())\n",
    "\n",
    "# Diccionario para guardar los modelos regionales para la celda siguiente\n",
    "modelos_regionales = {}\n",
    "\n",
    "for region_id in regiones_ordenadas:\n",
    "    df_region = df_join_pobre[df_join_pobre['REGION_CAT'] == region_id]\n",
    "    \n",
    "    if df_region.empty or df_region['V5_CAT'].nunique() < 2 or df_region['ESTADO_BIN'].nunique() < 2:\n",
    "        print(f\"  > Omitiendo Región {region_id}: datos insuficientes.\")\n",
    "        continue\n",
    "        \n",
    "    try:\n",
    "        pesos_reg = df_region['PONDERA2']\n",
    "        modelo_reg = smf.glm(formula=formula_simple, \n",
    "                             data=df_region, \n",
    "                             family=sm.families.Binomial(), \n",
    "                             freq_weights=pesos_reg).fit()\n",
    "        \n",
    "        # Guardamos el modelo regional\n",
    "        modelos_regionales[region_id] = modelo_reg\n",
    "        \n",
    "        # Extraer resultados\n",
    "        results_df_reg = pd.DataFrame({\n",
    "            'Coef. (Beta)': modelo_reg.params,\n",
    "            'Odds Ratio (e^Beta)': np.exp(modelo_reg.params), # Beta Exponenciado\n",
    "            'Error Estándar': modelo_reg.bse,\n",
    "            'P-Valor': modelo_reg.pvalues\n",
    "        })\n",
    "        \n",
    "        nagel_reg = get_nagelkerke_r2(modelo_reg)\n",
    "        results_df_reg.loc['Nagelkerke R²', 'Coef. (Beta)'] = nagel_reg\n",
    "        results_df_reg.loc['N (Ponderado)', 'Coef. (Beta)'] = modelo_reg.nobs\n",
    "        \n",
    "        results_df_reg['Modelo'] = 'Logístico Simple (Estratificado)'\n",
    "        results_df_reg['Estrato'] = region_id\n",
    "        results_df_reg = results_df_reg.reset_index().rename(columns={'index': 'Variable'})\n",
    "        \n",
    "        all_regression_results.append(results_df_reg)\n",
    "        print(f\"  > Región {region_id} calculada.\")\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"  > ERROR al calcular modelo para {region_id}: {e}\")\n",
    "\n",
    "# --- Guardar Pestaña 2 ---\n",
    "if all_regression_results:\n",
    "    # Combinar todos los resultados en un solo DataFrame\n",
    "    df_all_regressions = pd.concat(all_regression_results, ignore_index=True)\n",
    "    \n",
    "    # Reordenar columnas para mejor lectura\n",
    "    column_order = ['Modelo', 'Estrato', 'Variable', 'Coef. (Beta)', 'Odds Ratio (e^Beta)', 'Error Estándar', 'P-Valor']\n",
    "    df_all_regressions = df_all_regressions[column_order]\n",
    "    \n",
    "    # Formatear números\n",
    "    df_all_regressions['Coef. (Beta)'] = df_all_regressions['Coef. (Beta)'].round(4)\n",
    "    df_all_regressions['Odds Ratio (e^Beta)'] = df_all_regressions['Odds Ratio (e^Beta)'].round(4)\n",
    "    df_all_regressions['Error Estándar'] = df_all_regressions['Error Estándar'].round(4)\n",
    "    df_all_regressions['P-Valor'] = df_all_regressions['P-Valor'].map(lambda x: f\"{x:.4f}\" if isinstance(x, (int, float)) and not np.isnan(x) else \"\")\n",
    "    \n",
    "    # Escribir a la pestaña de regresión\n",
    "    df_all_regressions.to_excel(writer, sheet_name=sheet_name_reg, index=False)\n",
    "    print(f\"Pestaña '{sheet_name_reg}' generada.\")\n",
    "else:\n",
    "    print(\"No se generaron resultados de regresión.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "7096d029",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generando Pestaña 3: 'Evaluacion_Modelo'...\n",
      "  Calculando Matriz de Confusión (Nacional)...\n",
      "  > Matriz Nacional y Métricas guardadas.\n",
      "\n",
      "Cerrando y guardando el archivo Excel...\n",
      "¡Listo! Archivo 'Output_EPH_Transferencias_Actividad.xlsx' guardado con éxito con 3 pestañas.\n"
     ]
    }
   ],
   "source": [
    "# --- PESTAÑA 3: EVALUACIÓN DE MODELOS (MATRIZ DE CONFUSIÓN) ---\n",
    "\n",
    "# Importamos la función necesaria\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import numpy as np\n",
    "\n",
    "print(\"Generando Pestaña 3: 'Evaluacion_Modelo'...\")\n",
    "sheet_name_eval = 'Evaluacion_Modelo'\n",
    "fila_inicio = 0\n",
    "\n",
    "# --- 1. Evaluación Modelo Múltiple (Nacional) ---\n",
    "print(\"  Calculando Matriz de Confusión (Nacional)...\")\n",
    "\n",
    "try:\n",
    "    # Verificamos que 'modelo_nat' exista (creado en la celda anterior)\n",
    "    if 'modelo_nat' in locals():\n",
    "        df_nat = df_join_pobre\n",
    "        y_actual = df_nat['ESTADO_BIN']\n",
    "        y_pred_prob = modelo_nat.predict(df_nat)\n",
    "        y_pred_clase = (y_pred_prob > 0.5).astype(int) # Corte en 0.5\n",
    "        pesos = df_nat['PONDERA2']\n",
    "        \n",
    "        # Calcular la matriz de confusión PONDERADA\n",
    "        cm = confusion_matrix(y_actual, y_pred_clase, sample_weight=pesos)\n",
    "        \n",
    "        # Extraer VP, VN, FP, FN (cm[fila, col])\n",
    "        # Fila 0 = Realidad Inactivo(0), Fila 1 = Realidad Activo(1)\n",
    "        # Col 0 = Pred Inactivo(0), Col 1 = Pred Activo(1)\n",
    "        VN = cm[0, 0]\n",
    "        FP = cm[0, 1]\n",
    "        FN = cm[1, 0]\n",
    "        VP = cm[1, 1]\n",
    "        \n",
    "        Total = VN + FP + FN + VP\n",
    "        \n",
    "        # Calcular Métricas (evitando división por cero si un denominador es 0)\n",
    "        Accuracy = (VP + VN) / Total if Total > 0 else 0\n",
    "        Sensitivity = VP / (VP + FN) if (VP + FN) > 0 else 0\n",
    "        Specificity = VN / (VN + FP) if (VN + FP) > 0 else 0\n",
    "        FPR = FP / (VN + FP) if (VN + FP) > 0 else 0 # Tasa de Falsos Positivos\n",
    "        Precision = VP / (VP + FP) if (VP + FP) > 0 else 0\n",
    "        \n",
    "        # --- Escribir al Excel ---\n",
    "        \n",
    "        # Título de la Matriz\n",
    "        pd.DataFrame(['Matriz de Confusión - Modelo Múltiple (Nacional) (Ponderada)']).to_excel(\n",
    "            writer, sheet_name=sheet_name_eval, startrow=fila_inicio, index=False, header=False\n",
    "        )\n",
    "        fila_inicio += 2\n",
    "        \n",
    "        # DataFrame de Matriz de Confusión\n",
    "        matrix_df = pd.DataFrame(\n",
    "            [[VN, FP], [FN, VP]],\n",
    "            columns=pd.Index(['Predijo: Inactivo (0)', 'Predijo: Activo (1)'], name='Predicción'),\n",
    "            index=pd.Index(['Real: Inactivo (0)', 'Real: Activo (1)'], name='Realidad')\n",
    "        )\n",
    "        matrix_df.loc['Total_Pred'] = matrix_df.sum().values\n",
    "        matrix_df['Total_Real'] = matrix_df.sum(axis=1).values\n",
    "        \n",
    "        matrix_df.to_excel(writer, sheet_name=sheet_name_eval, startrow=fila_inicio)\n",
    "        fila_inicio += matrix_df.shape[0] + 3 # Espacio\n",
    "        \n",
    "        # Título de las Métricas\n",
    "        pd.DataFrame(['Métricas de Evaluación - Modelo Múltiple (Nacional) (Ponderada)']).to_excel(\n",
    "            writer, sheet_name=sheet_name_eval, startrow=fila_inicio, index=False, header=False\n",
    "        )\n",
    "        fila_inicio += 2\n",
    "        \n",
    "        # DataFrame de Métricas\n",
    "        metrics_df = pd.DataFrame({\n",
    "            'Metrica': [\n",
    "                'Verdaderos Positivos (VP)', 'Verdaderos Negativos (VN)',\n",
    "                'Falsos Positivos (FP)', 'Falsos Negativos (FN)',\n",
    "                'Total (N Ponderado)',\n",
    "                'Accuracy (Exactitud)',\n",
    "                'Sensitivity (Tasa VP / Recall)',\n",
    "                'Specificity (Tasa VN)',\n",
    "                'False Positive Rate (Tasa FP)',\n",
    "                'Precision'\n",
    "            ],\n",
    "            'Valor': [\n",
    "                VP, VN, FP, FN, Total,\n",
    "                Accuracy, Sensitivity, Specificity, FPR, Precision\n",
    "            ]\n",
    "        })\n",
    "        metrics_df['Valor'] = metrics_df['Valor'].round(4)\n",
    "        \n",
    "        metrics_df.to_excel(writer, sheet_name=sheet_name_eval, startrow=fila_inicio, index=False)\n",
    "        \n",
    "        print(\"  > Matriz Nacional y Métricas guardadas.\")\n",
    "\n",
    "    else:\n",
    "        print(\"  > 'modelo_nat' no encontrado. Asegúrate de correr la celda 12.\")\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"  > ERROR al calcular matriz de confusión nacional: {e}\")\n",
    "\n",
    "# --- CERRAR Y GUARDAR EL ARCHIVO EXCEL ---\n",
    "# Este es el paso final que guarda el archivo con las 3 pestañas.\n",
    "print(\"\\nCerrando y guardando el archivo Excel...\")\n",
    "writer.close()\n",
    "print(f\"¡Listo! Archivo '{output_filename}' guardado con éxito con 3 pestañas.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv (3.13.1)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
